# app/services/resume_parser_service.py
import asyncio
import pandas as pd
from pathlib import Path
from typing import Dict, Any, List, Optional
import logging

from app.utils.text_utils import dataframe_to_text
import time

from .extractors import (
    NameExtractor,
    GenderExtractor,
    AgeExtractor,
    BirthdateExtractor,
    NationalityExtractor,
    ArrivalYearExtractor,
    ExperienceExtractor,
    JapaneseLevelExtractor,
    SkillsExtractor,
    WorkScopeExtractor,
    RoleExtractor,
)

logger = logging.getLogger(__name__)


class ResumeParserService:
    """ç®€å†è§£ææœåŠ¡"""

    def __init__(self):
        """åˆå§‹åŒ–æ‰€æœ‰æå–å™¨"""
        self.name_extractor = NameExtractor()
        self.gender_extractor = GenderExtractor()
        self.age_extractor = AgeExtractor()
        self.birthdate_extractor = BirthdateExtractor()
        self.nationality_extractor = NationalityExtractor()
        self.arrival_year_extractor = ArrivalYearExtractor()
        self.experience_extractor = ExperienceExtractor()
        self.japanese_level_extractor = JapaneseLevelExtractor()
        self.skills_extractor = SkillsExtractor()
        self.work_scope_extractor = WorkScopeExtractor()
        self.role_extractor = RoleExtractor()

        logger.info("ç®€å†è§£ææœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    def _normalize_result(self, value: Any) -> Optional[Any]:
        """æ ‡å‡†åŒ–æå–ç»“æœ - å…³é”®ä¿®å¤å‡½æ•°

        Args:
            value: æå–çš„åŸå§‹å€¼

        Returns:
            æ ‡å‡†åŒ–åçš„å€¼ï¼š
            - ç©ºå­—ç¬¦ä¸² -> None
            - ç©ºåˆ—è¡¨ -> None
            - å…¶ä»–ç©ºå€¼ -> None
            - æœ‰æ•ˆå€¼ -> åŸå€¼
        """
        if value is None:
            return None

        # å¤„ç†å­—ç¬¦ä¸²
        if isinstance(value, str):
            value = value.strip()
            return value if value else None  # ç©ºå­—ç¬¦ä¸²è½¬æ¢ä¸ºNone

        # å¤„ç†åˆ—è¡¨
        if isinstance(value, list):
            return value if value else None  # ç©ºåˆ—è¡¨è½¬æ¢ä¸ºNone

        # å…¶ä»–ç±»å‹ç›´æ¥è¿”å›
        return value

    async def parse_resume(self, file_path: str) -> Dict[str, Any]:
        """
        è§£æç®€å†æ–‡ä»¶

        Args:
            file_path: Excelæ–‡ä»¶è·¯å¾„

        Returns:
            è§£æç»“æœå­—å…¸
        """
        start_time = time.time()

        try:
            # åœ¨å¼‚æ­¥ç¯å¢ƒä¸­è¿è¡ŒåŒæ­¥çš„pandasæ“ä½œ
            all_data = await asyncio.to_thread(self._load_excel_data, file_path)

            if not all_data:
                return {
                    "success": False,
                    "error": "æ— æ³•è¯»å–Excelæ–‡ä»¶æˆ–æ–‡ä»¶ä¸ºç©º",
                    "parse_time": time.time() - start_time,
                }

            # æå–å„é¡¹ä¿¡æ¯
            result = await self._extract_all_info(all_data)

            # åå¤„ç†
            result = await self._post_process(result)

            return {
                "success": True,
                "data": result,
                "error": None,
                "parse_time": time.time() - start_time,
            }

        except Exception as e:
            logger.error(f"è§£æç®€å†å¤±è´¥: {str(e)}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "parse_time": time.time() - start_time,
            }

    def _load_excel_data(self, file_path: str) -> List[Dict[str, Any]]:
        """åŠ è½½Excelæ•°æ®"""
        all_data = []
        file_obj = Path(file_path)

        # ä½¿ç”¨ä¸åŒçš„å¼•æ“å°è¯•è¯»å–
        engines = ["openpyxl", "xlrd"]

        for engine in engines:
            try:
                if file_obj.suffix == ".xls" and engine == "openpyxl":
                    continue
                if file_obj.suffix == ".xlsx" and engine == "xlrd":
                    continue

                excel_file = pd.ExcelFile(file_path, engine=engine)

                for sheet_name in excel_file.sheet_names:
                    try:
                        df = pd.read_excel(
                            excel_file,
                            sheet_name=sheet_name,
                            header=None,
                            dtype=str,
                            na_values=[""],
                            keep_default_na=False,
                        )

                        if not df.empty:
                            text = dataframe_to_text(df)
                            all_data.append(
                                {
                                    "sheet_name": sheet_name,
                                    "df": df,
                                    "text": text,
                                }
                            )

                    except Exception as e:
                        logger.warning(f"è¯»å–å·¥ä½œè¡¨ {sheet_name} å¤±è´¥: {e}")

                if all_data:
                    break

            except Exception as e:
                logger.warning(f"ä½¿ç”¨å¼•æ“ {engine} è¯»å–å¤±è´¥: {e}")
                continue

        return all_data

    async def _extract_all_info(self, all_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æå–æ‰€æœ‰ä¿¡æ¯"""
        # åœ¨å¼‚æ­¥ç¯å¢ƒä¸­è¿è¡ŒåŒæ­¥çš„æå–æ“ä½œ
        result = await asyncio.to_thread(self._sync_extract_all_info, all_data)
        return result

    def _sync_extract_all_info(self, all_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åŒæ­¥æå–æ‰€æœ‰ä¿¡æ¯ - å…³é”®ä¿®å¤ï¼šæ·»åŠ _normalize_resultè°ƒç”¨"""
        result = {}

        logger.info(f"å¼€å§‹æå–ä¿¡æ¯ï¼Œæ•°æ®é›†æ•°é‡: {len(all_data)}")

        # éªŒè¯æ•°æ®ç»“æ„
        for i, data in enumerate(all_data):
            logger.info(f"Sheet {i}: {data.get('sheet_name', 'Unknown')}")
            logger.info(f"  - åŒ…å«df: {'df' in data}")
            logger.info(f"  - åŒ…å«text: {'text' in data}")
            if "df" in data:
                df = data["df"]
                logger.info(f"  - DataFrameå½¢çŠ¶: {df.shape}")

        # æŒ‰é¡ºåºæå–å„é¡¹ä¿¡æ¯ - å…³é”®ä¿®å¤ï¼šæ¯ä¸ªå­—æ®µéƒ½è°ƒç”¨_normalize_result
        name_result = self.name_extractor.extract(all_data)
        result["name"] = self._normalize_result(name_result)
        logger.info(f"å§“åæå–ç»“æœ: {result['name']}")

        gender_result = self.gender_extractor.extract(all_data)
        result["gender"] = self._normalize_result(gender_result)
        logger.info(f"æ€§åˆ«æå–ç»“æœ: {result['gender']}")

        birthdate_result = self.birthdate_extractor.extract(all_data)
        result["birthdate"] = self._normalize_result(birthdate_result)
        logger.info(f"ç”Ÿæ—¥æå–ç»“æœ: {result['birthdate']}")

        age_result = self.age_extractor.extract(all_data, result["birthdate"])
        result["age"] = self._normalize_result(age_result)
        logger.info(f"å¹´é¾„æå–ç»“æœ: {result['age']}")

        nationality_result = self.nationality_extractor.extract(all_data)
        result["nationality"] = self._normalize_result(nationality_result)
        logger.info(f"å›½ç±æå–ç»“æœ: {result['nationality']}")

        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ¥æ—¥å¹´ä»½æå–ç»“æœæ ‡å‡†åŒ–
        arrival_result = self.arrival_year_extractor.extract(
            all_data, result["birthdate"]
        )
        result["arrival_year_japan"] = self._normalize_result(arrival_result)
        logger.info(f"æ¥æ—¥å¹´ä»½æå–ç»“æœ: {result['arrival_year_japan']}")

        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç»éªŒæå–ç»“æœæ ‡å‡†åŒ–
        experience_result = self.experience_extractor.extract(all_data)
        result["experience"] = self._normalize_result(experience_result)
        logger.info(f"ç»éªŒæå–ç»“æœ: {result['experience']}")

        japanese_result = self.japanese_level_extractor.extract(all_data)
        result["japanese_level"] = self._normalize_result(japanese_result)
        logger.info(f"æ—¥è¯­æ°´å¹³æå–ç»“æœ: {result['japanese_level']}")

        skills_result = self.skills_extractor.extract(all_data)
        result["skills"] = self._normalize_result(skills_result)
        logger.info(f"æŠ€èƒ½æå–ç»“æœ: {len(skills_result) if skills_result else 0}ä¸ª")

        work_scope_result = self.work_scope_extractor.extract(all_data)
        result["work_scope"] = self._normalize_result(work_scope_result)
        logger.info(f"å·¥ä½œèŒƒå›´æå–ç»“æœ: {result['work_scope']}")

        roles_result = self.role_extractor.extract(all_data)
        result["roles"] = self._normalize_result(roles_result)
        logger.info(f"è§’è‰²æå–ç»“æœ: {result['roles']}")

        return result

    async def _post_process(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """åå¤„ç†ç»“æœ - å·²æœ‰_normalize_resultå¤„ç†ï¼Œè¿™é‡Œä¸»è¦åšå»é‡ç­‰é€»è¾‘"""

        # æŠ€èƒ½å»é‡ï¼ˆå¦‚æœå·²ç»æœ‰å€¼çš„è¯ï¼‰
        if result.get("skills"):
            seen = set()
            unique_skills = []
            for skill in result["skills"]:
                if skill and skill.lower() not in seen:
                    seen.add(skill.lower())
                    unique_skills.append(skill)
            result["skills"] = unique_skills if unique_skills else None

        # æœ€ç»ˆå…œåº•å¤„ç†ï¼šç¡®ä¿æ‰€æœ‰Noneå€¼ç»Ÿä¸€
        for key, value in result.items():
            if value == "" or (isinstance(value, list) and len(value) == 0):
                result[key] = None

        return result

    async def parse_batch(self, file_paths: List[str]) -> Dict[str, Any]:
        """æ‰¹é‡è§£æç®€å†"""
        results = []
        success_count = 0
        failed_count = 0

        for file_path in file_paths:
            result = await self.parse_resume(file_path)

            if result["success"]:
                success_count += 1
            else:
                failed_count += 1

            results.append({"file_name": Path(file_path).name, "result": result})

        return {
            "total": len(file_paths),
            "success_count": success_count,
            "failed_count": failed_count,
            "results": results,
        }
