# -*- coding: utf-8 -*-
"""æŠ€èƒ½æå–å™¨ - æœ€ç»ˆå®Œæ•´ç‰ˆ"""

from typing import List, Dict, Any, Tuple, Optional
import pandas as pd
import re

from app.base.base_extractor import BaseExtractor
from app.base.constants import VALID_SKILLS, SKILL_MARKS, EXCLUDE_PATTERNS


class SkillsExtractor(BaseExtractor):
    """æŠ€èƒ½ä¿¡æ¯æå–å™¨"""

    def __init__(self):
        super().__init__()
        # å·¥ç¨‹é˜¶æ®µå…³é”®è¯ï¼ˆç”¨äºå®šä½å³ä¾§åˆ—ï¼‰
        self.design_keywords = [
            "åŸºæœ¬è¨­è¨ˆ",
            "è©³ç´°è¨­è¨ˆ",
            "è£½é€ ",
            "å˜ä½“ãƒ†ã‚¹ãƒˆ",
            "çµåˆãƒ†ã‚¹ãƒˆ",
            "ç·åˆãƒ†ã‚¹ãƒˆ",
            "é‹ç”¨ä¿å®ˆ",
            "è¦ä»¶å®šç¾©",
            "åŸºæœ¬è®¾è®¡",
            "è¯¦ç»†è®¾è®¡",
        ]

        # æŠ€æœ¯åˆ—æ ‡é¢˜å…³é”®è¯ï¼ˆç”¨äºè¯†åˆ«æŠ€æœ¯åˆ—ï¼‰
        self.tech_column_keywords = [
            "è¨€èª",
            "ãƒ„ãƒ¼ãƒ«",
            "æŠ€è¡“",
            "ã‚¹ã‚­ãƒ«",
            "DB",
            "OS",
            "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯",
            "é–‹ç™ºç’°å¢ƒ",
            "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°",
            "æ©Ÿç¨®",
            "Git",
            "SVN",
            "ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†",
        ]

        # ä¸åº”è¯¥è¢«ç©ºæ ¼åˆ†å‰²çš„æŠ€èƒ½ï¼ˆä¿æŒå®Œæ•´æ€§ï¼‰
        self.no_split_skills = {
            "Spring Boot",
            "VS Code",
            "Visual Studio",
            "Android Studio",
            "IntelliJ IDEA",
            "SQL Server",
            "Azure SQL Database",
            "Azure SQL DB",
            "React Native",
            "Node.js",
            "Vue.js",
            "React.js",
            "TeraTerm",
            "Tera Term",
            "Win95/98",
            "Finance and Operations",
            "Dynamics 365",
            "AWS Glue",
            "AWS S3",
            "AWS Lambda",
            "AWS EC2",
            "AWS IAM",
            "AWS CodeCommit",
        }

    def extract(self, all_data: List[Dict[str, Any]]) -> List[str]:
        """æå–æŠ€èƒ½åˆ—è¡¨ - åªæå–é¡¹ç›®ç»éªŒéƒ¨åˆ†çš„æŠ€èƒ½"""
        all_skills = []

        for data in all_data:
            df = data["df"]
            sheet_name = data.get("sheet_name", "Unknown")

            print(f"\nğŸ” å¼€å§‹æŠ€æœ¯å…³é”®å­—æå– - Sheet: {sheet_name}")
            print(f"    è¡¨æ ¼å¤§å°: {df.shape[0]}è¡Œ x {df.shape[1]}åˆ—")

            # ä»ä¸‹å¾€ä¸Šæ‰¾é¡¹ç›®è¡¨å¤´è¡Œ
            project_start_row = self._find_project_start_row(df)

            if project_start_row is not None:
                print(f"    âœ… æ‰¾åˆ°é¡¹ç›®è¡¨å¤´è¡Œ: ç¬¬{project_start_row + 1}è¡Œ")
                print(f"    ğŸ“ åªæå–ç¬¬{project_start_row + 1}è¡Œä¹‹ä¸‹çš„é¡¹ç›®ç»éªŒæŠ€èƒ½")

                # æ–¹æ³•1ï¼šé¡¹ç›®ç»éªŒè¡ŒæŠ€èƒ½æå–ï¼ˆä¸»è¦æ–¹æ³•ï¼‰
                project_skills = self._extract_project_row_skills(df, project_start_row)
                print(
                    f"    ğŸ“Š é¡¹ç›®ç»éªŒè¡Œæå–åˆ°: {len(project_skills)} ä¸ªæŠ€èƒ½: {project_skills}"
                )
                all_skills.extend(project_skills)

                # æ–¹æ³•2ï¼šé¡¹ç›®ç»éªŒåŒºåŸŸçš„æ¨ªå‘æŠ€èƒ½æå–ï¼ˆè¡¥å……æ–¹æ³•ï¼‰
                horizontal_skills = self._extract_skills_from_horizontal_table_limited(
                    df, project_start_row
                )
                print(
                    f"    ğŸ“Š é¡¹ç›®ç»éªŒæ¨ªå‘æå–åˆ°: {len(horizontal_skills)} ä¸ªæŠ€èƒ½: {horizontal_skills}"
                )
                all_skills.extend(horizontal_skills)

                # å¦‚æœæŠ€èƒ½è¿˜æ˜¯å¤ªå°‘ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•ï¼ˆä»…é™é¡¹ç›®ç»éªŒåŒºåŸŸï¼‰
                if len(all_skills) < 15:
                    print(f"    æŠ€èƒ½æ•°é‡ä¸è¶³ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•è¡¥å……ï¼ˆä»…é™é¡¹ç›®ç»éªŒåŒºåŸŸï¼‰")
                    fallback_skills = self._extract_skills_fallback_limited(
                        df, project_start_row
                    )
                    print(
                        f"    ğŸ“Š å¤‡ç”¨æ–¹æ³•æå–åˆ°: {len(fallback_skills)} ä¸ªæŠ€èƒ½: {fallback_skills}"
                    )
                    all_skills.extend(fallback_skills)

                print(f"    ğŸ“Š æ‰€æœ‰æ–¹æ³•å…±æå–åˆ°: {len(all_skills)} ä¸ªåŸå§‹æŠ€èƒ½")
            else:
                print("    âŒ æœªæ‰¾åˆ°é¡¹ç›®è¡¨å¤´å…³é”®è¯ï¼Œæ— æ³•ç¡®å®šæå–èŒƒå›´")
                print("    ğŸš« è·³è¿‡è¯¥è¡¨æ ¼ï¼Œä¸è¿›è¡Œä»»ä½•æŠ€èƒ½æå–")

        # å»é‡å’Œæ ‡å‡†åŒ–
        print(f"\nğŸ”„ å¼€å§‹å»é‡å’Œæ ‡å‡†åŒ–...")
        print(f"    è¾“å…¥æŠ€èƒ½æ•°é‡: {len(all_skills)}")
        final_skills = self._process_and_deduplicate_skills(all_skills)

        final_skills = [
            re.sub(r"\s+", " ", skill.strip())
            for skill in final_skills
            if skill and isinstance(skill, str)
        ]

        final_skills = self._split_valid_skills(final_skills)
        print(f"    è¾“å‡ºæŠ€èƒ½æ•°é‡: {len(final_skills)}")

        return final_skills

    def _find_project_start_row(self, df: pd.DataFrame) -> Optional[int]:
        """ä»ä¸‹å¾€ä¸Šæ‰¾åˆ°é¡¹ç›®è¡¨å¤´è¡Œï¼ˆåŒ…å«é …ç•ªã€ä½œæ¥­æœŸé–“ç­‰çš„è¡Œï¼‰

        Returns:
            é¡¹ç›®è¡¨å¤´è¡Œå·ï¼Œå¦‚æœæ²¡æ‰¾åˆ°åˆ™è¿”å›None
        """
        project_header_keywords = [
            "é …ç•ª",
            "ä½œæ¥­æœŸé–“",
            "é–‹ç™ºå ´æ‰€",
            "è¨€èª",
            "ãƒ„ãƒ¼ãƒ«",
            "DB",
        ]

        # **å…³é”®ä¿®å¤ï¼šä»ä¸‹å¾€ä¸ŠæŸ¥æ‰¾ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªå°±åœæ­¢**
        for row in range(len(df) - 1, -1, -1):  # ä»æœ€åä¸€è¡Œå¾€ä¸Šæ‰¾
            for col in range(len(df.columns)):
                cell = df.iloc[row, col]
                if pd.notna(cell):
                    cell_str = str(cell).strip()
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«é¡¹ç›®è¡¨å¤´å…³é”®è¯
                    if any(keyword in cell_str for keyword in project_header_keywords):
                        print(
                            f"    å‘ç°é¡¹ç›®è¡¨å¤´: ç¬¬{row + 1}è¡Œ,ç¬¬{col + 1}åˆ— = '{cell_str}'"
                        )
                        return row  # **æ‰¾åˆ°ç¬¬ä¸€ä¸ªå°±ç«‹å³è¿”å›ï¼Œä¸å†ç»§ç»­æŸ¥æ‰¾**

        return None

    def _extract_project_row_skills(
        self, df: pd.DataFrame, project_start_row: int
    ) -> List[str]:
        """æå–é¡¹ç›®ç»éªŒè¡Œä¸­çš„æŠ€èƒ½ï¼ˆä¸“é—¨å¤„ç†é¡¹ç›®æ•°æ®è¡Œï¼‰- ä¿®å¤ç‰ˆæœ¬"""
        skills = []

        print(f"    ä½¿ç”¨é¡¹ç›®ç»éªŒè¡Œæå–æ–¹æ³•ï¼ˆä»ç¬¬{project_start_row + 1}è¡Œä¹‹ä¸‹ï¼‰...")

        # **å…³é”®ä¿®å¤ï¼šä»project_start_row+1å¼€å§‹æŸ¥æ‰¾é¡¹ç›®æ•°æ®è¡Œ**
        for row in range(project_start_row + 1, len(df)):
            row_data = df.iloc[row]

            # **ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦æ˜¯é¡¹ç›®æ•°æ®è¡Œï¼ˆç¬¬ä¸€åˆ—é€šå¸¸æ˜¯é¡¹ç›®ç¼–å·ï¼‰**
            first_cell = row_data.iloc[0] if len(row_data) > 0 else None
            if pd.notna(first_cell):
                first_cell_str = str(first_cell).strip()
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å­—é¡¹ç›®ç¼–å·
                if first_cell_str.isdigit():
                    print(
                        f"        å‘ç°é¡¹ç›®æ•°æ®è¡Œ: ç¬¬{row + 1}è¡Œï¼Œé¡¹ç›®ç¼–å·: {first_cell_str}"
                    )

                    # **å…³é”®ä¿®å¤ï¼šæŸ¥æ‰¾åŒ…å«æŠ€èƒ½çš„åˆ—**
                    for col_idx in range(len(row_data)):
                        cell = row_data.iloc[col_idx]
                        if pd.notna(cell):
                            cell_str = str(cell).strip()

                            # **ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«æ¢è¡Œç¬¦åˆ†éš”çš„å¤šä¸ªæŠ€èƒ½**
                            if "\r\n" in cell_str or "\n" in cell_str:
                                lines = re.split(r"\r?\n", cell_str)
                                tech_lines = []
                                for line in lines:
                                    line = line.strip()
                                    if line and self._is_likely_tech_skill(line):
                                        tech_lines.append(line)

                                if len(tech_lines) >= 2:  # è‡³å°‘2ä¸ªæŠ€èƒ½æ‰è®¤ä¸ºæ˜¯æŠ€èƒ½åˆ—
                                    print(
                                        f"            ç¬¬{col_idx + 1}åˆ—åŒ…å«{len(tech_lines)}ä¸ªæŠ€èƒ½:"
                                    )
                                    for line in tech_lines:
                                        if self._is_valid_skill(line):
                                            normalized = self._normalize_skill_name(
                                                line
                                            )
                                            skills.append(normalized)
                                            print(
                                                f"              - {line} -> {normalized}"
                                            )

                            # **ä¿®å¤ï¼šæ£€æŸ¥å•ä¸ªæŠ€èƒ½ï¼ˆæ•°æ®åº“åç­‰ï¼‰**
                            elif self._is_likely_single_tech_skill(cell_str):
                                if self._is_valid_skill(cell_str):
                                    normalized = self._normalize_skill_name(cell_str)
                                    skills.append(normalized)
                                    print(
                                        f"            ç¬¬{col_idx + 1}åˆ—å•ä¸ªæŠ€èƒ½: {cell_str} -> {normalized}"
                                    )

        print(f"    é¡¹ç›®ç»éªŒè¡Œæå–å®Œæˆï¼Œå…±æ‰¾åˆ° {len(skills)} ä¸ªæŠ€èƒ½")
        return skills

    def _is_likely_tech_skill(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯æŠ€æœ¯æŠ€èƒ½"""
        if not text or len(text) < 2 or len(text) > 30:
            return False

        # æ’é™¤æ˜æ˜¾éæŠ€èƒ½çš„å†…å®¹
        if text in ["â—", "â—‹", "â—", "â–³", "Ã—"]:
            return False
        if text.isdigit():
            return False
        if text.upper() in ["PM", "PL", "SL", "TL", "BSE", "SE", "PG"]:
            return False

        # ğŸ”¥ ä¿®å¤ï¼šæ·»åŠ å¯¹æ‹¬å·çš„æ”¯æŒ
        # å¸¸è§æŠ€èƒ½æ¨¡å¼
        tech_patterns = [
            r"^[A-Za-z#][A-Za-z0-9#\s\.\+\-\(\)]*$",  # ğŸ”¥ æ·»åŠ äº† # å’Œ \(\) æ”¯æŒ C# ASP.NET(MVC 5)
            r"^[A-Za-z][A-Za-z0-9]*\.[A-Za-z][A-Za-z0-9]*$",  # å¦‚ Node.js
            r"^[A-Za-z]+[0-9]*$",  # å¦‚ HTML5
        ]

        return any(re.match(pattern, text) for pattern in tech_patterns)

    def _is_likely_single_tech_skill(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯å•ä¸ªæŠ€æœ¯æŠ€èƒ½"""
        # å¸¸è§çš„å•ä¸ªæŠ€èƒ½ï¼ˆæ•°æ®åº“ã€æ“ä½œç³»ç»Ÿç­‰ï¼‰
        common_single_skills = [
            "PostgreSQL",
            "MySQL",
            "Oracle",
            "Windows",
            "Linux",
            "macOS",
            "MongoDB",
            "Redis",
            "SQLite",
            "DB2",
            "Access",
        ]

        return text in common_single_skills or self._is_likely_tech_skill(text)

    def _extract_skills_from_horizontal_table_limited(
        self, df: pd.DataFrame, project_start_row: int
    ) -> List[str]:
        """
        å¤„ç†æ¨ªå‘å¤šåˆ—æŠ€èƒ½è¡¨æ ¼ï¼ˆé™åˆ¶åœ¨project_start_rowä¹‹ä¸‹ï¼‰- ä¿®å¤ç‰ˆæœ¬
        **åªå¤„ç†é¡¹ç›®ç»éªŒéƒ¨åˆ†ï¼Œä¸å¤„ç†ç®€å†ä¸ŠåŠéƒ¨åˆ†çš„æŠ€èƒ½è¡¨æ ¼**
        """
        skills = []

        print(
            f"    ä½¿ç”¨æ¨ªå‘è¡¨æ ¼æå–æ–¹æ³•ï¼ˆåªå¤„ç†ç¬¬{project_start_row + 1}è¡Œä¹‹ä¸‹çš„é¡¹ç›®ç»éªŒï¼‰..."
        )

        # **ä¿®å¤ï¼šåªæŸ¥æ‰¾project_start_rowä¹‹ä¸‹çš„é¡¹ç›®ç»éªŒåŒºåŸŸ**
        for row in range(project_start_row + 1, len(df)):
            row_data = df.iloc[row]

            # æ£€æŸ¥è¯¥è¡Œæ˜¯å¦åŒ…å«é¡¹ç›®ç›¸å…³çš„æŠ€èƒ½ä¿¡æ¯
            # è·³è¿‡é¡¹ç›®æ•°æ®è¡Œï¼ŒæŸ¥æ‰¾é¡¹ç›®è¯´æ˜è¡Œæˆ–å…¶ä»–åŒ…å«æŠ€èƒ½çš„è¡Œ
            first_cell = row_data.iloc[0] if len(row_data) > 0 else None

            # è·³è¿‡é¡¹ç›®ç¼–å·è¡Œï¼ˆç”±æ–¹æ³•1å¤„ç†ï¼‰
            if pd.notna(first_cell) and str(first_cell).strip().isdigit():
                continue

            # æŸ¥æ‰¾åŒ…å«æŠ€èƒ½çš„è¡Œ
            for col_idx, cell in enumerate(row_data):
                if pd.notna(cell):
                    cell_str = str(cell).strip()

                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤šä¸ªæŠ€èƒ½ï¼ˆç”¨æ¢è¡Œç¬¦åˆ†éš”ï¼‰
                    if "\r\n" in cell_str or "\n" in cell_str:
                        lines = re.split(r"\r?\n", cell_str)
                        tech_count = 0
                        for line in lines:
                            line = line.strip()
                            if line and self._is_likely_tech_skill(line):
                                tech_count += 1

                        # å¦‚æœåŒ…å«å¤šä¸ªæŠ€èƒ½ï¼Œæå–å®ƒä»¬
                        if tech_count >= 2:
                            print(
                                f"        ç¬¬{row + 1}è¡Œç¬¬{col_idx + 1}åˆ—åŒ…å«{tech_count}ä¸ªæŠ€èƒ½:"
                            )
                            for line in lines:
                                line = line.strip()
                                if line and self._is_likely_tech_skill(line):
                                    if self._is_valid_skill(line):
                                        normalized = self._normalize_skill_name(line)
                                        skills.append(normalized)
                                        print(f"            - {line} -> {normalized}")

        print(f"    æ¨ªå‘è¡¨æ ¼æå–å®Œæˆï¼Œå…±æ‰¾åˆ° {len(skills)} ä¸ªæŠ€èƒ½")
        return skills

    def _extract_skills_fallback_limited(
        self, df: pd.DataFrame, project_start_row: int
    ) -> List[str]:
        """å…¨æ–‡æœç´¢æŠ€èƒ½ï¼ˆæœ€åçš„å¤‡ç”¨æ–¹æ³•ï¼Œé™åˆ¶åœ¨project_start_rowä¹‹ä¸‹ï¼‰"""
        skills = []

        print(f"    ä½¿ç”¨å¤‡ç”¨å…¨æ–‡æœç´¢ï¼ˆé™åˆ¶åœ¨ç¬¬{project_start_row + 1}è¡Œä¹‹ä¸‹ï¼‰")

        # **å…³é”®ä¿®å¤ï¼šåªå°†project_start_rowä¹‹ä¸‹çš„å†…å®¹è½¬æ¢ä¸ºæ–‡æœ¬**
        text_parts = []
        for idx in range(project_start_row, len(df)):
            row = df.iloc[idx]
            row_text = " ".join([str(cell) for cell in row if pd.notna(cell)])
            if row_text.strip():
                text_parts.append(row_text)

        text = "\n".join(text_parts)

        for skill in VALID_SKILLS:
            patterns = [
                rf"\b{re.escape(skill)}\b",
                rf"(?:^|\s|[ã€,ï¼Œ/]){re.escape(skill)}(?:$|\s|[ã€,ï¼Œ/])",
            ]

            for pattern in patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    skills.append(skill)
                    break

        return skills

    def _extract_skills_from_text(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–æŠ€èƒ½"""
        skills = []
        text = text.strip()

        if not text:
            return skills

        # ç§»é™¤æ ‡è®°ç¬¦å·
        text = re.sub(r"^[â—â—‹â–³Ã—â˜…â—â—¯â–²â€»ãƒ»\-\s]+", "", text)

        # å¤„ç†æ‹¬å·å†…çš„å†…å®¹
        # ä¾‹å¦‚: "Python AWS (glue/S3/Lambda/EC2/IAM/codecommit)"
        bracket_pattern = r"([^(]+)\s*\(([^)]+)\)"
        bracket_match = re.match(bracket_pattern, text)

        if bracket_match:
            # æ‹¬å·å‰çš„å†…å®¹
            main_part = bracket_match.group(1)
            # æ‹¬å·å†…çš„å†…å®¹
            bracket_content = bracket_match.group(2)

            # æå–ä¸»è¦éƒ¨åˆ†çš„æŠ€èƒ½
            main_skills = self._split_and_validate_skills(main_part)
            skills.extend(main_skills)

            # æå–æ‹¬å·å†…çš„æŠ€èƒ½ï¼ˆé€šå¸¸æ˜¯å…·ä½“çš„æœåŠ¡/æ¨¡å—ï¼‰
            bracket_skills = self._split_and_validate_skills(bracket_content)
            skills.extend(bracket_skills)
        else:
            # æ²¡æœ‰æ‹¬å·ï¼Œç›´æ¥æå–
            skills.extend(self._split_and_validate_skills(text))

        return skills

    def _split_and_validate_skills(self, text: str) -> List[str]:
        """åˆ†å‰²æ–‡æœ¬å¹¶éªŒè¯æŠ€èƒ½"""
        skills = []

        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ä¸åº”è¯¥è¢«åˆ†å‰²çš„æŠ€èƒ½
        text_stripped = text.strip()

        # æ£€æŸ¥å®Œæ•´æ–‡æœ¬æ˜¯å¦åŒ¹é…ä¸å¯åˆ†å‰²æŠ€èƒ½ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        for no_split_skill in self.no_split_skills:
            if text_stripped.lower() == no_split_skill.lower():
                if self._is_valid_skill(text_stripped):
                    normalized = self._normalize_skill_name(text_stripped)
                    skills.append(normalized)
                    return skills

        # ä¿æŠ¤ä¸å¯åˆ†å‰²çš„æŠ€èƒ½ï¼šå°†å®ƒä»¬ä¸´æ—¶æ›¿æ¢ä¸ºå ä½ç¬¦
        protected_skills = {}
        protected_text = text
        placeholder_index = 0

        for no_split_skill in self.no_split_skills:
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œä¸åŒºåˆ†å¤§å°å†™çš„åŒ¹é…
            pattern = re.compile(re.escape(no_split_skill), re.IGNORECASE)
            if pattern.search(protected_text):
                placeholder = f"__SKILL_PLACEHOLDER_{placeholder_index}__"
                protected_skills[placeholder] = no_split_skill
                protected_text = pattern.sub(placeholder, protected_text)
                placeholder_index += 1

        # ä½¿ç”¨å¤šç§åˆ†éš”ç¬¦åˆ†å‰²ï¼ˆä½†ä¸åŒ…æ‹¬è¢«ä¿æŠ¤çš„æŠ€èƒ½ï¼‰
        items = re.split(r"[ã€,ï¼Œ/ï¼\s\|ï½œ]+", protected_text)

        for item in items:
            item = item.strip()
            if not item:
                continue

            # æ£€æŸ¥æ˜¯å¦æ˜¯å ä½ç¬¦
            if item in protected_skills:
                # æ¢å¤åŸå§‹æŠ€èƒ½
                original_skill = protected_skills[item]
                if self._is_valid_skill(original_skill):
                    normalized = self._normalize_skill_name(original_skill)
                    skills.append(normalized)
            else:
                # æ™®é€šæŠ€èƒ½éªŒè¯
                if self._is_valid_skill(item):
                    normalized = self._normalize_skill_name(item)
                    skills.append(normalized)

        # å¦‚æœåˆ†å‰²åæ²¡æœ‰æ‰¾åˆ°æŠ€èƒ½ï¼Œå°è¯•å°†æ•´ä¸ªæ–‡æœ¬ä½œä¸ºæŠ€èƒ½
        if not skills and text and self._is_valid_skill(text):
            normalized = self._normalize_skill_name(text)
            skills.append(normalized)

        return skills

    def _is_valid_skill(self, skill: str) -> bool:
        """éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆæŠ€èƒ½ - ä¿®å¤ç‰ˆæœ¬"""
        if not skill or len(skill) < 1 or len(skill) > 50:
            return False

        skill = skill.strip()

        # **ä¿®å¤ï¼šæ’é™¤å ä½ç¬¦**
        if "__SKILL_PLACEHOLDER_" in skill:
            return False

        # **ä¿®å¤ï¼šä¸å†ç›´æ¥æ’é™¤åŒ…å«"os"æˆ–"db"çš„æŠ€èƒ½**
        # è€Œæ˜¯æ›´ç²¾ç¡®åœ°æ’é™¤
        skill_lower = skill.lower()

        # åªæ’é™¤æ˜ç¡®çš„éæŠ€èƒ½å†…å®¹ï¼Œè€Œä¸æ˜¯åŒ…å«os/dbçš„æ‰€æœ‰å†…å®¹
        if skill_lower in ["os", "db"]:  # åªæ’é™¤å•ç‹¬çš„"os"å’Œ"db"
            return False

        # æ’é™¤åŒ…å«"æ•°æ®åº“"ã€"æ“ä½œç³»ç»Ÿ"ç­‰å®Œæ•´è¯æ±‡çš„æè¿°æ€§æ–‡æœ¬
        if any(word in skill for word in ["æ•°æ®åº“", "æ“ä½œç³»ç»Ÿ", "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"]):
            return False

        # æ’é™¤åŒ…å«æ‹¬å·çš„æŠ€èƒ½ï¼ˆåŠè§’å’Œå…¨è§’ï¼‰
        # if any(bracket in skill for bracket in ["(", ")", "ï¼ˆ", "ï¼‰"]):
        #     return False

        # æ’é™¤åŒ…å«æ—¥æ–‡å…³é”®è¯çš„éæŠ€èƒ½å†…å®¹
        exclude_japanese_keywords = [
            "è‡ªå·±PR",
            "è‡ªå·±ç´¹ä»‹",
            "å¿—æœ›å‹•æ©Ÿ",
            "ã‚¢ãƒ”ãƒ¼ãƒ«",
            "ãƒã‚¤ãƒ³ãƒˆ",
            "çµŒæ­´æ›¸",
            "å±¥æ­´æ›¸",
            "ã‚¹ã‚­ãƒ«ã‚·ãƒ¼ãƒˆ",
            "è·å‹™çµŒæ­´",
            "æ°å",
            "æ€§åˆ¥",
            "ç”Ÿå¹´æœˆæ—¥",
            "å¹´é½¢",
            "ä½æ‰€",
            "é›»è©±",
            "å­¦æ­´",
            "è·æ­´",
            "è³‡æ ¼",
            "è¶£å‘³",
            "ç‰¹æŠ€",
            "å‚™è€ƒ",
        ]
        if any(keyword in skill for keyword in exclude_japanese_keywords):
            return False

        # æ’é™¤è¯„ä»·ç¬¦å·
        if skill in ["â—", "â—‹", "â–³", "Ã—", ""]:
            return False

        # æ’é™¤æ¨¡å¼
        exclude_patterns = [
            r"^[0-9\s\.\-]+$",  # çº¯æ•°å­—
            r"^[â—â—‹â–³Ã—\s]+$",  # è¯„ä»·ç¬¦å·
        ]

        for pattern in exclude_patterns:
            if re.match(pattern, skill):
                return False

        # ç‰¹æ®Šæƒ…å†µ
        if skill.upper() == "C":
            return True

        # ç‰¹æ®Šæ’é™¤ï¼šèŒä½æ ‡è®°
        if skill.upper() in ["PM", "PL", "SL", "TL", "BSE", "SE", "PG"]:
            return False

        # æ£€æŸ¥é¢„å®šä¹‰æŠ€èƒ½åˆ—è¡¨
        skill_upper = skill.upper()
        for valid_skill in VALID_SKILLS:
            if valid_skill.upper() == skill_upper:
                return True

        # æ“ä½œç³»ç»Ÿæ¨¡å¼
        if re.match(r"^win\d+$", skill_lower) or re.match(
            r"^Windows\s*\d+$", skill, re.IGNORECASE
        ):
            return True

        # åŒ…å«æŠ€æœ¯å…³é”®è¯
        if re.search(r"[a-zA-Z]", skill) and len(skill) >= 2:
            exclude_words = [
                "è¨­è¨ˆ",
                "è£½é€ ",
                "è©¦é¨“",
                "ãƒ†ã‚¹ãƒˆ",
                "ç®¡ç†",
                "çµŒé¨“",
                "æ‹…å½“",
                "å½¹å‰²",
                "ãƒ•ã‚§ãƒ¼ã‚º",
            ]
            if not any(word in skill for word in exclude_words):
                return True

        return False

    def _normalize_skill_name(self, skill: str) -> str:
        """æ ‡å‡†åŒ–æŠ€èƒ½åç§° - å¢å¼ºç‰ˆæœ¬"""
        skill = skill.strip()

        # å¤„ç†å†’å·åˆ†éš”çš„æƒ…å†µï¼ˆæ”¯æŒå…¨è§’å’ŒåŠè§’å†’å·ï¼‰
        # ä¾‹å¦‚: "è¨€èª:Java" -> "Java", "DBï¼šPostgreSQL" -> "PostgreSQL"
        if ":" in skill or "ï¼š" in skill:
            # æ›¿æ¢å…¨è§’å†’å·ä¸ºåŠè§’ï¼Œç„¶ååˆ†å‰²
            skill_parts = skill.replace("ï¼š", ":").split(":", 1)
            if len(skill_parts) == 2:
                # å–å†’å·åé¢çš„éƒ¨åˆ†
                skill = skill_parts[1].strip()
                # å¦‚æœå†’å·åé¢ä¸ºç©ºï¼Œè¿”å›åŸå§‹å€¼
                if not skill:
                    skill = skill_parts[0].strip()

        # ç‰¹æ®Šå¤„ç†ï¼šæ“ä½œç³»ç»Ÿæ ‡å‡†åŒ–
        # å¦‚æœåŒ…å« Windowsï¼ˆæ— è®ºå¤§å°å†™ï¼‰ï¼Œç»Ÿä¸€è¿”å› Windows
        if "windows" in skill.lower():
            return "Windows"

        # å¦‚æœåŒ…å« Linuxï¼ˆæ— è®ºå¤§å°å†™ï¼‰ï¼Œç»Ÿä¸€è¿”å› Linux
        if "linux" in skill.lower():
            return "Linux"

        # **å¢å¼ºçš„æŠ€èƒ½åç§°æ˜ å°„**
        skill_mapping = {
            # ç¼–ç¨‹è¯­è¨€
            "JAVA": "Java",
            "java": "Java",
            "Javascript": "JavaScript",
            "javascript": "JavaScript",
            "JAVASCRIPT": "JavaScript",
            "typescript": "TypeScript",
            "TYPESCRIPT": "TypeScript",
            "python": "Python",
            "PYTHON": "Python",
            "C#": "C#",
            "c#": "C#",
            "C++": "C++",
            "c++": "C++",
            "C": "C",
            "c": "C",
            "PHP": "PHP",
            "php": "PHP",
            "Ruby": "Ruby",
            "ruby": "Ruby",
            "GO": "Go",
            "go": "Go",
            "VBï¼NET": "VB.NET",
            "VB.NET": "VB.NET",
            "ASPï¼NET": "ASP.NET",
            "ASP.NET": "ASP.NET",
            "COBOL": "COBOL",
            "cobol": "COBOL",
            "Groovy": "Groovy",
            "groovy": "Groovy",
            "Objective-C": "Objective-C",
            "objective-c": "Objective-C",
            "Swift": "Swift",
            "swift": "Swift",
            "Kotlin": "Kotlin",
            "kotlin": "Kotlin",
            "HTML5": "HTML5",
            "html5": "HTML5",
            "HTML": "HTML",
            "html": "HTML",
            "CSS": "CSS",
            "css": "CSS",
            # æ•°æ®åº“
            "MySql": "MySQL",
            "mysql": "MySQL",
            "MYSQL": "MySQL",
            "mybatis": "MyBatis",
            "Mybatis": "MyBatis",
            "MYBATIS": "MyBatis",
            "PostgreSQL": "PostgreSQL",
            "Postgre SQL": "PostgreSQL",
            "postgresql": "PostgreSQL",
            "SqlServer": "SQL Server",
            "SQLServer": "SQL Server",
            "sqlserver": "SQL Server",
            "SQL SERVER": "SQL Server",
            "ORACLE": "Oracle",
            "oracle": "Oracle",
            "Oracle": "Oracle",
            "DB2": "DB2",
            "db2": "DB2",
            "ACCESS": "Access",
            "access": "Access",
            "Access": "Access",
            "ADABAS": "ADABAS",
            "adabas": "ADABAS",
            "HIRDB": "HiRDB",
            "hirdb": "HiRDB",
            # æ¡†æ¶
            "spring": "Spring",
            "Spring": "Spring",
            "SPRING": "Spring",
            "spring boot": "Spring Boot",
            "springboot": "Spring Boot",
            "spring-boot": "Spring Boot",
            "SPRING BOOT": "Spring Boot",
            "SpringBoot": "Spring Boot",  # **é‡è¦ï¼šå¤„ç†è¿™ä¸ªå˜ä½“**
            "SpringMVC": "Spring MVC",
            "springmvc": "Spring MVC",
            "Struts1.0": "Struts 1.0",
            "struts1.0": "Struts 1.0",
            "Struts2.0": "Struts 2.0",
            "struts2.0": "Struts 2.0",
            "thymeleaf": "Thymeleaf",
            "Thymeleaf": "Thymeleaf",
            "THYMELEAF": "Thymeleaf",
            "Angular": "Angular",
            "angular": "Angular",
            "ANGULAR": "Angular",
            "AngularJS": "AngularJS",
            "angularjs": "AngularJS",
            "ANGULARJS": "AngularJS",
            "jQuery": "jQuery",
            "jquery": "jQuery",
            "JQUERY": "jQuery",
            "node.js": "Node.js",
            "Node.JS": "Node.js",
            "nodejs": "Node.js",
            "NODE.JS": "Node.js",
            "vue.js": "Vue.js",
            "Vue.js": "Vue.js",
            "vuejs": "Vue.js",
            "VUE.JS": "Vue.js",
            "react.js": "React",
            "React.js": "React",
            "reactjs": "React",
            "REACT.JS": "React",
            "JSF": "JSF",
            "jsf": "JSF",
            "BackBone.js": "Backbone.js",
            "backbone.js": "Backbone.js",
            # æµ‹è¯•å’Œæ„å»ºå·¥å…·
            "junit": "JUnit",
            "Junit": "JUnit",
            "JUNIT": "JUnit",
            "Spock": "Spock",
            "spock": "Spock",
            "Jmeter": "JMeter",
            "jmeter": "JMeter",
            "JMETER": "JMeter",
            "A5M2": "A5:SQL Mk-2",
            "a5m2": "A5:SQL Mk-2",
            # IDEå’Œå·¥å…·
            "eclipse": "Eclipse",
            "Eclipse": "Eclipse",
            "ECLIPSE": "Eclipse",
            "eclipes": "Eclipse",  # **ä¿®å¤æ‹¼å†™é”™è¯¯**
            "vscode": "VS Code",
            "Vscode": "VS Code",
            "VSCode": "VS Code",
            "VS Code": "VS Code",
            "vs code": "VS Code",
            "VS code": "VS Code",
            "Visual Studio Code": "VS Code",
            "Visual Studio": "Visual Studio",
            "visual studio": "Visual Studio",
            "Intellij": "IntelliJ IDEA",
            "intellij": "IntelliJ IDEA",
            "IntelliJ": "IntelliJ IDEA",
            "postman": "Postman",
            "Postman": "Postman",
            "POSTMAN": "Postman",
            "WinMerge": "WinMerge",
            "winmerge": "WinMerge",
            "WINMERGE": "WinMerge",
            # ç‰ˆæœ¬æ§åˆ¶
            "git": "Git",
            "Git": "Git",
            "GIT": "Git",
            "github": "GitHub",
            "Github": "GitHub",
            "GITHUB": "GitHub",
            "svn": "SVN",
            "Svn": "SVN",
            "SVN": "SVN",
            "TortoiseSVN": "TortoiseSVN",
            "tortoisesvn": "TortoiseSVN",
            # äº‘æœåŠ¡
            "aws": "AWS",
            "Aws": "AWS",
            "AWS": "AWS",
            "azure": "Azure",
            "Azure": "Azure",
            "AZURE": "Azure",
            "SalseForce": "Salesforce",
            "salesforce": "Salesforce",
            "Salesforce": "Salesforce",
            "OutSystems": "OutSystems",
            "outsystems": "OutSystems",
            # æ“ä½œç³»ç»Ÿ
            "Solris": "Solaris",
            "solaris": "Solaris",
            "Solaris": "Solaris",
            "UNIX": "Unix",
            "unix": "Unix",
            "Unix": "Unix",
            "Linux": "Linux",
            "linux": "Linux",
            "LINUX": "Linux",
            "DOS": "DOS",
            "dos": "DOS",
            "Mac": "macOS",
            "mac": "macOS",
            "macOS": "macOS",
            "MacOS": "macOS",
            "iOS": "iOS",
            "ios": "iOS",
            "Android": "Android",
            "android": "Android",
            "ANDROID": "Android",
            # åä½œå·¥å…·
            "slack": "Slack",
            "Slack": "Slack",
            "SLACK": "Slack",
            "teams": "Teams",
            "Teams": "Teams",
            "TEAMS": "Teams",
            "ovice": "oVice",
            "Ovice": "oVice",
            "oVice": "oVice",
            # å…¶ä»–å·¥å…·
            "teraterm": "TeraTerm",
            "TeraTerm": "TeraTerm",
            "TERATERM": "TeraTerm",
            "Tera Term": "TeraTerm",
        }

        # æ£€æŸ¥æ˜ å°„
        if skill in skill_mapping:
            return skill_mapping[skill]

        # å¤§å°å†™ä¸æ•æ„ŸæŸ¥æ‰¾
        skill_lower = skill.lower()
        for k, v in skill_mapping.items():
            if k.lower() == skill_lower:
                return v

        # æ£€æŸ¥æœ‰æ•ˆæŠ€èƒ½åˆ—è¡¨
        for valid_skill in VALID_SKILLS:
            if valid_skill.lower() == skill_lower:
                return valid_skill

        # å¦‚æœåœ¨no_split_skillsä¸­æœ‰å¯¹åº”çš„æŠ€èƒ½ï¼Œä½¿ç”¨æ ‡å‡†å½¢å¼
        for no_split_skill in self.no_split_skills:
            if skill.lower() == no_split_skill.lower():
                return no_split_skill

        return skill

    def _process_and_deduplicate_skills(self, skills: List[str]) -> List[str]:
        """å¤„ç†å’Œå»é‡æŠ€èƒ½åˆ—è¡¨"""
        final_skills = []
        seen_lower = set()

        for skill in skills:
            if not skill:
                continue

            normalized = self._normalize_skill_name(skill)
            normalized_lower = normalized.lower()

            # å»é‡ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
            if normalized_lower not in seen_lower:
                seen_lower.add(normalized_lower)
                final_skills.append(normalized)

        # ä¿æŒåŸå§‹é¡ºåºï¼Œä¸è¿›è¡Œæ’åº
        print(f"    æœ€ç»ˆæå–æŠ€èƒ½æ•°é‡: {len(final_skills)}")
        if final_skills:
            print(f"    å‰10ä¸ªæŠ€èƒ½: {', '.join(final_skills[:10])}")

        return final_skills

    def _dataframe_to_text(self, df: pd.DataFrame) -> str:
        """å°†DataFrameè½¬æ¢ä¸ºæ–‡æœ¬"""
        text_parts = []
        for idx, row in df.iterrows():
            row_text = " ".join([str(cell) for cell in row if pd.notna(cell)])
            if row_text.strip():
                text_parts.append(row_text)
        return "\n".join(text_parts)

    # ä¿æŒå…¼å®¹æ€§çš„æ–¹æ³•ï¼ˆé¿å…å…¶ä»–åœ°æ–¹è°ƒç”¨å‡ºé”™ï¼‰
    def _find_min_design_row(self, df: pd.DataFrame) -> Optional[int]:
        """å…¼å®¹æ€§æ–¹æ³•ï¼šé‡å®šå‘åˆ°æ–°çš„é¡¹ç›®è¡¨å¤´æŸ¥æ‰¾æ–¹æ³•"""
        return self._find_project_start_row(df)

    def _extract_skills_by_design_column(
        self, df: pd.DataFrame
    ) -> Tuple[List[str], List[Dict]]:
        """åŸºäºå·¥ç¨‹é˜¶æ®µåˆ—å®šä½å¹¶æå–æŠ€æœ¯åˆ—ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰"""
        return [], []

    def _find_skills_in_merged_cells(
        self, df: pd.DataFrame, design_positions: List[Dict]
    ) -> List[str]:
        """æŸ¥æ‰¾åˆå¹¶å•å…ƒæ ¼ä¸­çš„æŠ€èƒ½ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        skills = []

        # è·å–æœ€æ—©çš„è®¾è®¡è¡Œä½ç½®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        min_design_row = 0
        if design_positions:
            min_design_row = min(pos["row"] for pos in design_positions)

        for row in range(min_design_row, len(df)):  # åªæœç´¢è®¾è®¡è¡Œä¸‹æ–¹
            for col in range(len(df.columns)):
                cell = df.iloc[row, col]
                if pd.notna(cell) and "\n" in str(cell):
                    cell_str = str(cell)
                    lines = cell_str.split("\n")

                    # è®¡ç®—åŒ…å«æŠ€èƒ½çš„è¡Œæ•°
                    skill_count = 0
                    for line in lines:
                        if self._cell_contains_tech_content(line):
                            skill_count += 1

                    # å¦‚æœå¤šè¡ŒåŒ…å«æŠ€èƒ½ï¼Œæå–æ‰€æœ‰
                    if skill_count >= 3:
                        for line in lines:
                            line_skills = self._extract_skills_from_text(line)
                            skills.extend(line_skills)

        return skills

    def _extract_skills_fallback(
        self, df: pd.DataFrame, design_positions: List[Dict]
    ) -> List[str]:
        """å…¨æ–‡æœç´¢æŠ€èƒ½ï¼ˆæœ€åçš„å¤‡ç”¨æ–¹æ³•ï¼‰"""
        skills = []

        # åªæœç´¢è®¾è®¡è¡Œä¸‹æ–¹çš„æ–‡æœ¬
        min_design_row = 0
        if design_positions:
            min_design_row = min(pos["row"] for pos in design_positions)

        # åªå°†è®¾è®¡è¡Œä¸‹æ–¹çš„å†…å®¹è½¬æ¢ä¸ºæ–‡æœ¬
        text_parts = []
        for idx in range(min_design_row, len(df)):
            row = df.iloc[idx]
            row_text = " ".join([str(cell) for cell in row if pd.notna(cell)])
            if row_text.strip():
                text_parts.append(row_text)

        text = "\n".join(text_parts)

        for skill in VALID_SKILLS:
            patterns = [
                rf"\b{re.escape(skill)}\b",
                rf"(?:^|\s|[ã€,ï¼Œ/]){re.escape(skill)}(?:$|\s|[ã€,ï¼Œ/])",
            ]

            for pattern in patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    skills.append(skill)
                    break

        return skills

    def _cell_contains_tech_content(self, cell_str: str) -> bool:
        """æ£€æŸ¥å•å…ƒæ ¼æ˜¯å¦åŒ…å«æŠ€æœ¯å†…å®¹"""
        # å¿«é€Ÿæ£€æŸ¥å¸¸è§æŠ€æœ¯å…³é”®è¯
        tech_patterns = [
            r"\b(Java|Python|JavaScript|PHP|Ruby|C\+\+|C#|Go|VB|COBOL)\b",
            r"\b(Spring|React|Vue|Angular|Django|Rails|Node\.js|\.NET)\b",
            r"\b(MySQL|PostgreSQL|Oracle|MongoDB|Redis|SQL\s*Server|DB2)\b",
            r"\b(AWS|Azure|GCP|Docker|Kubernetes)\b",
            r"\b(Git|SVN|Jenkins|Maven|TortoiseSVN|GitHub)\b",
            r"\b(Windows|Linux|Unix|Ubuntu|CentOS|win\d+)\b",
            r"\b(Eclipse|IntelliJ|VS\s*Code|Visual\s*Studio|NetBeans)\b",
            r"(HTML|CSS|SQL|XML|JSON|TeraTerm)",
        ]

        cell_upper = cell_str.upper()
        for pattern in tech_patterns:
            if re.search(pattern, cell_str, re.IGNORECASE):
                return True

        # æ£€æŸ¥æ˜¯å¦åŒ…å«é¢„å®šä¹‰çš„æœ‰æ•ˆæŠ€èƒ½
        for skill in VALID_SKILLS:
            if skill.upper() in cell_upper:
                return True

        # ç‰¹æ®Šæƒ…å†µï¼šå•ç‹¬çš„"SE"æˆ–"PG"ä¸ç®—æŠ€èƒ½ï¼Œä½†åœ¨æŠ€æœ¯åˆ—ä¸­å¯èƒ½å‡ºç°
        if cell_str in ["SE", "PG", "PL", "PM"]:
            return False

        return False

    def _split_valid_skills(self, final_skills):
        """
        æ™ºèƒ½æ‹†åˆ†æŠ€èƒ½åˆ—è¡¨ä¸­çš„å¤åˆæŠ€èƒ½
        è¿™ä¸ªæ–¹æ³•å¯ä»¥ç›´æ¥æ·»åŠ åˆ° SkillsExtractor ç±»ä¸­
        """
        # å¯¼å…¥æœ‰æ•ˆæŠ€èƒ½åˆ—è¡¨
        try:
            from app.base.constants import VALID_SKILLS
        except ImportError:
            try:
                from app.utils.resume_constants import VALID_SKILLS
            except ImportError:
                # ä½¿ç”¨å†…ç½®çš„æ ¸å¿ƒæŠ€èƒ½åˆ—è¡¨
                VALID_SKILLS = {
                    "Java",
                    "Python",
                    "JavaScript",
                    "TypeScript",
                    "C",
                    "C++",
                    "C#",
                    "PHP",
                    "Ruby",
                    "Go",
                    "Eclipse",
                    "IntelliJ",
                    "VS Code",
                    "React",
                    "Vue",
                    "Angular",
                    "Spring",
                    "SpringBoot",
                    "Node.js",
                    "MySQL",
                    "PostgreSQL",
                    "Oracle",
                    "MongoDB",
                    "Git",
                    "GitHub",
                    "SVN",
                    "Docker",
                    "AWS",
                    "Azure",
                    "HTML",
                    "CSS",
                    "Bootstrap",
                    "jQuery",
                }

        if not final_skills:
            return final_skills

        # å¤„ç† VALID_SKILLS çš„ä¸åŒæ ¼å¼
        if isinstance(VALID_SKILLS, (list, tuple)):
            valid_skills_set = set(VALID_SKILLS)
        else:
            valid_skills_set = VALID_SKILLS

        # åˆ›å»ºä¸åŒºåˆ†å¤§å°å†™çš„æ˜ å°„
        skill_mapping = {}
        for skill in valid_skills_set:
            if isinstance(skill, str):
                skill_mapping[skill.lower()] = skill

        result_skills = []

        for skill in final_skills:
            if not skill or not isinstance(skill, str):
                continue

            skill = skill.strip()
            if not skill:
                continue

            # æŒ‰ç©ºæ ¼æ‹†åˆ†
            parts = skill.split()

            if len(parts) <= 1:
                # å•ä¸ªè¯ï¼Œç›´æ¥æ·»åŠ 
                result_skills.append(skill)
            else:
                # å¤šä¸ªè¯ï¼Œæ£€æŸ¥æ‹†åˆ†
                valid_parts = []

                for part in parts:
                    part_clean = part.strip()
                    if part_clean.lower() in skill_mapping:
                        # ä½¿ç”¨æ ‡å‡†æ ¼å¼çš„æŠ€èƒ½åç§°
                        valid_parts.append(skill_mapping[part_clean.lower()])
                    else:
                        # æ£€æŸ¥å¸¸è§å˜ä½“
                        variants = {
                            "eclipse": "Eclipse",
                            "eclipes": "Eclipse",
                            "intellij": "IntelliJ",
                            "vscode": "VS Code",
                            "github": "GitHub",
                            "springboot": "SpringBoot",
                            "nodejs": "Node.js",
                            "mysql": "MySQL",
                        }

                        if part_clean.lower() in variants:
                            valid_parts.append(variants[part_clean.lower()])

                if len(valid_parts) >= 2:
                    # æˆåŠŸæ‹†åˆ†ä¸ºå¤šä¸ªæœ‰æ•ˆæŠ€èƒ½
                    print(f"ğŸ”§ æ‹†åˆ†æŠ€èƒ½: '{skill}' -> {valid_parts}")
                    result_skills.extend(valid_parts)
                else:
                    # æ— æ³•æœ‰æ•ˆæ‹†åˆ†ï¼Œä¿æŒåŸæ ·
                    result_skills.append(skill)

        # å»é‡
        seen = set()
        final_result = []

        for skill in result_skills:
            if skill and skill.lower() not in seen:
                seen.add(skill.lower())
                final_result.append(skill)

        return final_result
