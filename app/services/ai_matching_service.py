# app/services/ai_matching_service.py
import asyncio
import json
import time
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any, Tuple, Union
from uuid import UUID, uuid4
import logging
import numpy as np
import re
from sentence_transformers import SentenceTransformer

from ..database import (
    get_db_connection,
    get_db_transaction,
    fetch_one,
    fetch_all,
    fetch_val,
    execute_query,
)
from ..schemas.ai_matching_schemas import (
    ProjectToEngineersMatchRequest,
    EngineerToProjectsMatchRequest,
    BulkMatchingRequest,
    MatchResult,
    MatchingHistoryResponse,
    AIMatchingResponse,
    ProjectToEngineersResponse,
    EngineerToProjectsResponse,
    BulkMatchingResponse,
)

logger = logging.getLogger(__name__)


class AIMatchingService:
    """AIåŒ¹é…æœåŠ¡ - æ´¾é£ä¸“ç”¨ç®€åŒ–ç‰ˆï¼ˆä»…æŠ€èƒ½+ç»éªŒ+æ—¥è¯­ï¼‰"""

    def __init__(self):
        self.model = None
        self.model_version = "paraphrase-multilingual-mpnet-base-v2"
        self._load_model()

    def _load_model(self):
        """åŠ è½½embeddingæ¨¡å‹"""
        try:
            logger.info(f"æ­£åœ¨åŠ è½½AIæ¨¡å‹: {self.model_version}")
            self.model = SentenceTransformer(self.model_version)
            logger.info("AIæ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.error(f"AIæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            raise Exception(f"æ— æ³•åŠ è½½AIæ¨¡å‹: {str(e)}")

    def _serialize_for_db(self, value: Union[Dict[str, Any], List, None]) -> str:
        """åºåˆ—åŒ–æ•°æ®ä¸ºæ•°æ®åº“JSONBå­—æ®µ"""
        if value is None:
            return json.dumps({})
        try:
            return json.dumps(value, ensure_ascii=False)
        except (TypeError, ValueError) as e:
            logger.warning(f"åºåˆ—åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç©ºå¯¹è±¡: {e}")
            return json.dumps({})

    def _parse_jsonb_field(self, value: Union[str, dict, None]) -> Dict[str, Any]:
        """å®‰å…¨è§£æJSONBå­—æ®µ"""
        if value is None:
            return {}
        if isinstance(value, dict):
            return value
        if isinstance(value, str):
            try:
                return json.loads(value) if value.strip() else {}
            except (json.JSONDecodeError, ValueError):
                logger.warning(f"æ— æ³•è§£æJSONå­—ç¬¦ä¸²: {value}")
                return {}
        return {}

    def _format_matching_history(self, history_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–åŒ¹é…å†å²æ•°æ®"""
        history_data["ai_config"] = self._parse_jsonb_field(
            history_data.get("ai_config")
        )
        history_data["statistics"] = self._parse_jsonb_field(
            history_data.get("statistics")
        )
        history_data["filters"] = self._parse_jsonb_field(history_data.get("filters"))

        if isinstance(history_data.get("project_ids"), str):
            try:
                history_data["project_ids"] = json.loads(history_data["project_ids"])
            except:
                history_data["project_ids"] = []
        elif history_data.get("project_ids") is None:
            history_data["project_ids"] = []

        if isinstance(history_data.get("engineer_ids"), str):
            try:
                history_data["engineer_ids"] = json.loads(history_data["engineer_ids"])
            except:
                history_data["engineer_ids"] = []
        elif history_data.get("engineer_ids") is None:
            history_data["engineer_ids"] = []

        return history_data

    def _parse_vector_string(self, vector_str) -> np.ndarray:
        """å°†PostgreSQL vectorå­—ç¬¦ä¸²è½¬æ¢ä¸ºnumpyæ•°ç»„"""
        try:
            if not vector_str:
                return np.array([])

            if isinstance(vector_str, str):
                vector_str = vector_str.strip()
                if vector_str.startswith("[") and vector_str.endswith("]"):
                    vector_str = vector_str[1:-1]

                if vector_str:
                    values = [
                        float(x.strip()) for x in vector_str.split(",") if x.strip()
                    ]
                    return np.array(values, dtype=np.float32)
                else:
                    return np.array([])
            elif isinstance(vector_str, (list, tuple)):
                return np.array(vector_str, dtype=np.float32)
            else:
                return np.array([])

        except Exception as e:
            logger.error(f"è§£ævectorå¤±è´¥: {str(e)}")
            return np.array([])

    def _validate_similarity_score(self, score: float, context: str = "") -> float:
        """éªŒè¯å’Œä¿®æ­£ç›¸ä¼¼åº¦åˆ†æ•°"""
        if score is None or not isinstance(score, (int, float)):
            logger.warning(f"æ— æ•ˆç›¸ä¼¼åº¦åˆ†æ•° {context}: {score}, ä½¿ç”¨é»˜è®¤å€¼")
            return 0.5

        if not (0 <= score <= 1):
            logger.warning(f"ç›¸ä¼¼åº¦åˆ†æ•°è¶…å‡ºèŒƒå›´ {context}: {score}, è¿›è¡Œä¿®æ­£")
            if score > 10:
                score = 1.0
            elif score < -10:
                score = 0.0
            elif score > 1:
                score = 1.0
            elif score < 0:
                score = 0.0

        return float(score)

    # ========== æ–°å¢ï¼šå¹´é™æå–æ–¹æ³• ==========

    def _extract_experience_years(self, experience_text: str) -> int:
        """
        ä»ç»éªŒæè¿°ä¸­æå–å¹´é™æ•°å­—

        æ”¯æŒæ ¼å¼ï¼š
        - "3å¹´ä»¥ä¸Š" â†’ 3
        - "5å¹´é–“ã®ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰é–‹ç™º" â†’ 5
        - "Reacté–‹ç™º2å¹´ä»¥ä¸Š" â†’ 2
        - "10å¹´è¿‘ãã®çµŒé¨“" â†’ 10
        """
        if not experience_text:
            return 0

        # æ—¥è¯­å¹´é™æå–æ­£åˆ™æ¨¡å¼
        patterns = [
            r"(\d+)å¹´ä»¥ä¸Š",  # æœ€å¸¸è§ï¼š3å¹´ä»¥ä¸Š
            r"(\d+)å¹´é–“",  # æœŸé—´è¡¨è¾¾ï¼š5å¹´é–“
            r"(\d+)å¹´ã®",  # æ‰€æœ‰æ ¼ï¼š3å¹´ã®çµŒé¨“
            r"(\d+)å¹´è¿‘ã",  # æ¥è¿‘ï¼š5å¹´è¿‘ã
            r"(\d+)å¹´ç¨‹åº¦",  # ç¨‹åº¦ï¼š3å¹´ç¨‹åº¦
            r"(\d+)å¹´ç›®",  # ç¬¬å‡ å¹´ï¼š5å¹´ç›®
            r"(\d+)å¹´ã»ã©",  # å¤§çº¦ï¼š3å¹´ã»ã©
            r"(\d+)å¹´çµŒé¨“",  # ç›´æ¥ï¼š5å¹´çµŒé¨“
            r"(\d+)å¹´",  # å…œåº•æ¨¡å¼
        ]

        for pattern in patterns:
            match = re.search(pattern, experience_text)
            if match:
                years = int(match.group(1))
                logger.debug(f"æå–å¹´é™: '{experience_text}' â†’ {years}å¹´")
                return years

        logger.debug(f"æœªèƒ½æå–å¹´é™: '{experience_text}'")
        return 0

    def _calculate_experience_match(
        self, project_years: int, engineer_years: int
    ) -> float:
        """
        è®¡ç®—ç»éªŒå¹´é™åŒ¹é…åˆ†æ•°

        æ´¾é£å¹´é™åŒ¹é…è§„åˆ™ï¼š
        1. æ»¡è¶³è¦æ±‚ï¼š100%åŒ¹é…
        2. è¶…å‡ºè¦æ±‚ä½†åˆç†ï¼š95%åŒ¹é…
        3. è¿‡åº¦è¶…å‡ºï¼šé€‚å½“æ‰£åˆ†ï¼ˆover-qualifiedï¼‰
        4. ä¸è¶³è¦æ±‚ï¼šæŒ‰æ¯”ä¾‹æ‰£åˆ†
        """
        if project_years <= 0:
            # æ²¡æœ‰æ˜ç¡®å¹´é™è¦æ±‚
            return 0.8 if engineer_years > 0 else 0.6

        if engineer_years >= project_years:
            # æ»¡è¶³æˆ–è¶…è¿‡è¦æ±‚
            if engineer_years <= project_years * 1.5:
                return 1.0  # åˆç†èŒƒå›´å†…
            elif engineer_years <= project_years * 2:
                return 0.95  # è½»å¾®over-qualified
            else:
                return 0.85  # æ˜æ˜¾over-qualifiedä½†ä»å¯ç”¨
        else:
            # ä¸æ»¡è¶³è¦æ±‚
            if engineer_years == 0:
                return 0.3  # æ²¡æœ‰ç»éªŒ
            else:
                # æŒ‰æ¯”ä¾‹è®¡ç®—ï¼Œä½†è®¾æœ€ä½åˆ†
                ratio = engineer_years / project_years
                return max(0.4, ratio)

    # ========== æ ¸å¿ƒä¿®æ”¹ï¼šç®€åŒ–ç‰ˆè¯¦ç»†åŒ¹é…åˆ†æ•°è®¡ç®— ==========

    def _calculate_detailed_match_scores(
        self, project: Dict[str, Any], engineer: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ğŸ”¥ æ´¾é£ä¸“ç”¨ç®€åŒ–ç‰ˆè¯¦ç»†åŒ¹é…åˆ†æ•°è®¡ç®—

        ä»…å…³æ³¨ä¸‰ä¸ªæ ¸å¿ƒç»´åº¦ï¼š
        1. æŠ€èƒ½åŒ¹é… (skill_match)
        2. ç»éªŒå¹´é™åŒ¹é… (experience_match)
        3. æ—¥è¯­æ°´å¹³åŒ¹é… (japanese_level_match)

        ç§»é™¤æ‰€æœ‰å¤æ‚çš„å…³é”®è¯æƒé‡ç³»ç»Ÿ
        """
        scores = {}

        # ==================== 1. æŠ€èƒ½åŒ¹é…ï¼ˆæ´¾é£æœ€é‡è¦ï¼‰ ====================
        project_skills = set(project.get("skills", []))
        engineer_skills = set(engineer.get("skills", []))

        if project_skills:
            matched_skills = project_skills.intersection(engineer_skills)
            skill_score = len(matched_skills) / len(project_skills)

            scores["matched_skills"] = list(matched_skills)
            scores["missing_skills"] = list(project_skills - engineer_skills)
            scores["skill_match"] = skill_score
        else:
            scores["matched_skills"] = []
            scores["missing_skills"] = []
            scores["skill_match"] = 0.5  # æ²¡æœ‰æŠ€èƒ½è¦æ±‚æ—¶ç»™ä¸­æ€§åˆ†æ•°

        # ==================== 2. ç»éªŒå¹´é™åŒ¹é…ï¼ˆç®€åŒ–ä¸ºçº¯å¹´é™æ¯”è¾ƒï¼‰ ====================
        project_years = self._extract_experience_years(project.get("experience", ""))
        engineer_years = self._extract_experience_years(engineer.get("experience", ""))

        experience_score = self._calculate_experience_match(
            project_years, engineer_years
        )

        scores["experience_match"] = experience_score
        scores["project_required_years"] = project_years
        scores["engineer_experience_years"] = engineer_years

        # ==================== 3. æ—¥è¯­æ°´å¹³åŒ¹é…ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰ ====================
        project_jp = project.get("japanese_level", "")
        engineer_jp = engineer.get("japanese_level", "")

        # æ—¥è¯­ç­‰çº§æ•°å€¼åŒ–æ˜ å°„
        jp_levels = {
            "N5": 1,
            "N4": 2,
            "N3": 3,
            "N2": 4,
            "N1": 5,
            "ãƒã‚¤ãƒ†ã‚£ãƒ–": 6,
            "native": 6,
            "æ¯è¯­": 6,
            "ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«": 5.5,
            "ãƒ“ã‚¸ãƒã‚¹": 5.5,
            "": 0,
        }

        project_jp_score = jp_levels.get(project_jp, 0)
        engineer_jp_score = jp_levels.get(engineer_jp, 0)

        if project_jp_score > 0:
            if engineer_jp_score >= project_jp_score:
                scores["japanese_level_match"] = 1.0
            elif engineer_jp_score > 0:
                scores["japanese_level_match"] = engineer_jp_score / project_jp_score
            else:
                scores["japanese_level_match"] = 0.2
        else:
            scores["japanese_level_match"] = 0.9 if engineer_jp_score > 0 else 0.7

        # ç¡®ä¿æ‰€æœ‰åˆ†æ•°åœ¨[0,1]èŒƒå›´å†…
        for key in ["skill_match", "experience_match", "japanese_level_match"]:
            if key in scores:
                scores[key] = max(0, min(1, scores[key]))

        return scores

    # ========== ä¿®æ”¹ï¼šç®€åŒ–ç‰ˆæƒé‡è®¡ç®— ==========

    def _calculate_weighted_score(
        self,
        detailed_scores: Dict[str, Any],
        weights: Dict[str, float],
        similarity_score: float,
    ) -> float:
        """
        ğŸ”¥ æ´¾é£ä¸“ç”¨ç®€åŒ–ç‰ˆæƒé‡è®¡ç®—
        """
        # éªŒè¯ç›¸ä¼¼åº¦åˆ†æ•°
        similarity_score = self._validate_similarity_score(
            similarity_score, "è¯­ä¹‰ç›¸ä¼¼åº¦"
        )

        # ğŸ”¥ æ´¾é£ä¸“ç”¨é»˜è®¤æƒé‡ï¼ˆåªæœ‰ä¸‰ä¸ªç»´åº¦ï¼‰
        dispatch_default_weights = {
            "skill_match": 0.5,  # æŠ€èƒ½åŒ¹é… 50%
            "experience_match": 0.3,  # ç»éªŒå¹´é™ 30%
            "japanese_level_match": 0.2,  # æ—¥è¯­æ°´å¹³ 20%
        }

        # åˆå¹¶æƒé‡é…ç½®
        final_weights = {**dispatch_default_weights, **weights}

        # è®¡ç®—ç»“æ„åŒ–åŒ¹é…åˆ†æ•°
        weighted_sum = 0
        total_weight = 0

        for score_type, weight in final_weights.items():
            if (
                score_type in detailed_scores
                and detailed_scores[score_type] is not None
            ):
                score = max(0, min(1, float(detailed_scores[score_type])))
                weighted_sum += score * weight
                total_weight += weight

        base_score = weighted_sum / total_weight if total_weight > 0 else 0
        base_score = max(0, min(1, base_score))

        # ğŸ”¥ æ´¾é£é‡è§†æ˜ç¡®åŒ¹é…ï¼Œé™ä½AIè¯­ä¹‰ç›¸ä¼¼åº¦æƒé‡
        # ç»“æ„åŒ–åŒ¹é… 80% + è¯­ä¹‰ç›¸ä¼¼åº¦ 20%
        final_score = base_score * 0.8 + similarity_score * 0.2

        return max(0, min(1, final_score))

    # ========== ç®€åŒ–ç‰ˆåŒ¹é…åˆ†æç”Ÿæˆ ==========

    def _generate_match_analysis(
        self, project: Dict[str, Any], engineer: Dict[str, Any], scores: Dict[str, Any]
    ) -> Tuple[List[str], List[str]]:
        """
        ğŸ”¥ ç®€åŒ–ç‰ˆåŒ¹é…åˆ†æç”Ÿæˆ
        """
        reasons = []
        concerns = []

        # æŠ€èƒ½åˆ†æ
        skill_score = scores.get("skill_match", 0)
        if skill_score >= 0.8:
            matched_skills = scores.get("matched_skills", [])
            if matched_skills:
                reasons.append(f"æŠ€èƒ½é«˜åº¦åŒ¹é…: {', '.join(matched_skills)}")
            else:
                reasons.append("æŠ€èƒ½åŒ¹é…åº¦é«˜")
        elif skill_score < 0.5:
            concerns.append("æŠ€èƒ½åŒ¹é…åº¦è¾ƒä½")
            missing_skills = scores.get("missing_skills", [])
            if missing_skills:
                concerns.append(f"ç¼ºå°‘æŠ€èƒ½: {', '.join(missing_skills)}")

        # ç»éªŒå¹´é™åˆ†æ
        exp_score = scores.get("experience_match", 0)
        project_years = scores.get("project_required_years", 0)
        engineer_years = scores.get("engineer_experience_years", 0)

        if exp_score >= 0.9 and project_years > 0:
            reasons.append(f"ç»éªŒæ»¡è¶³è¦æ±‚ ({engineer_years}å¹´ >= {project_years}å¹´)")
        elif exp_score < 0.5 and project_years > 0:
            concerns.append(f"ç»éªŒä¸è¶³ ({engineer_years}å¹´ < {project_years}å¹´)")
        elif engineer_years > project_years * 2 and project_years > 0:
            concerns.append(
                f"å¯èƒ½over-qualified ({engineer_years}å¹´ >> {project_years}å¹´)"
            )

        # æ—¥è¯­æ°´å¹³åˆ†æ
        jp_score = scores.get("japanese_level_match", 0)
        if jp_score >= 0.9:
            reasons.append("æ—¥è¯­æ°´å¹³æ»¡è¶³è¦æ±‚")
        elif jp_score < 0.5:
            concerns.append("æ—¥è¯­æ°´å¹³å¯èƒ½ä¸è¶³")

        return reasons, concerns

    # ========== ä¿®å¤çš„ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³• ==========

    async def _calculate_similarities_batch(
        self,
        target_embedding: List[float],
        candidates: List[Dict[str, Any]],
        table_type: str,
    ) -> List[Tuple[Dict[str, Any], float]]:
        """ä¿®å¤ç‰ˆï¼šæ‰¹é‡è®¡ç®—ç›¸ä¼¼åº¦"""
        if not candidates:
            return []

        candidate_ids = [c["id"] for c in candidates]
        table_name = "engineers" if table_type == "engineers" else "projects"

        # ğŸ”§ ä¿®å¤ï¼šé™ä½æœ€å°åˆ†æ•°é˜ˆå€¼ï¼Œé¿å…è¿‡æ»¤æ‰æ‰€æœ‰ç»“æœ
        query = f"""
        SELECT id, 
               ai_match_embedding <=> $1 as cosine_distance
        FROM {table_name}
        WHERE id = ANY($2) AND ai_match_embedding IS NOT NULL
        ORDER BY ai_match_embedding <=> $1 ASC
        """

        try:
            similarities = await fetch_all(query, target_embedding, candidate_ids)
            logger.info(f"ä»æ•°æ®åº“è·å–åˆ° {len(similarities)} ä¸ªç›¸ä¼¼åº¦ç»“æœ")
        except Exception as e:
            logger.error(f"pgvectoræŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°æ‰‹åŠ¨è®¡ç®—: {str(e)}")
            return await self._manual_similarity_calculation(
                target_embedding, candidates
            )

        results = []
        similarity_dict = {}

        for s in similarities:
            cosine_distance = s["cosine_distance"]

            if cosine_distance is None or not isinstance(cosine_distance, (int, float)):
                logger.warning(f"æ— æ•ˆçš„ä½™å¼¦è·ç¦»å€¼: {cosine_distance}")
                continue

            # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿è·ç¦»å€¼åœ¨åˆç†èŒƒå›´å†…
            cosine_distance = max(0, min(2, float(cosine_distance)))
            similarity_score = 1 - cosine_distance
            similarity_score = max(0, min(1, similarity_score))

            similarity_dict[s["id"]] = similarity_score

        # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿æŒ‰åŸå§‹candidatesé¡ºåºè¿”å›ç»“æœ
        for candidate in candidates:
            if candidate["id"] in similarity_dict:
                similarity_score = similarity_dict[candidate["id"]]
                results.append((candidate, similarity_score))

        logger.info(f"æˆåŠŸè®¡ç®— {len(results)} ä¸ªç›¸ä¼¼åº¦åˆ†æ•°")
        if results:
            scores = [r[1] for r in results]
            logger.info(f"ç›¸ä¼¼åº¦åˆ†æ•°èŒƒå›´: {min(scores):.3f} - {max(scores):.3f}")

        return results

    async def _manual_similarity_calculation(
        self, target_embedding, candidates
    ) -> List[Tuple[Dict[str, Any], float]]:
        """æ‰‹åŠ¨è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰"""
        logger.info("ä½¿ç”¨æ‰‹åŠ¨ç›¸ä¼¼åº¦è®¡ç®—")

        results = []
        target_vector = self._parse_vector_string(target_embedding)

        if target_vector.size == 0:
            logger.warning("ç›®æ ‡å‘é‡è§£æå¤±è´¥ï¼Œæ— æ³•è®¡ç®—ç›¸ä¼¼åº¦")
            return results

        target_norm = np.linalg.norm(target_vector)
        if target_norm == 0:
            logger.warning("ç›®æ ‡å‘é‡æ¨¡é•¿ä¸º0ï¼Œæ— æ³•è®¡ç®—ç›¸ä¼¼åº¦")
            return results

        for candidate in candidates:
            try:
                candidate_embedding = candidate.get("ai_match_embedding")
                if not candidate_embedding:
                    continue

                candidate_vector = self._parse_vector_string(candidate_embedding)

                if candidate_vector.size == 0:
                    continue

                candidate_norm = np.linalg.norm(candidate_vector)
                if candidate_norm == 0:
                    continue

                dot_product = np.dot(target_vector, candidate_vector)
                cosine_similarity = dot_product / (target_norm * candidate_norm)

                cosine_similarity = (cosine_similarity + 1) / 2
                cosine_similarity = max(0, min(1, cosine_similarity))

                results.append((candidate, cosine_similarity))

            except Exception as e:
                logger.error(f"æ‰‹åŠ¨è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥: {candidate['id']}, é”™è¯¯: {str(e)}")
                continue

        results.sort(key=lambda x: x[1], reverse=True)
        return results

    # ========== ä¿å­˜åŒ¹é…ç»“æœæ–¹æ³• ==========

    async def _save_matches(
        self, matches: List[MatchResult], matching_history_id: UUID
    ) -> List[MatchResult]:
        """ä¿å­˜åŒ¹é…ç»“æœ"""
        if not matches:
            return []

        saved_matches = []

        async with get_db_connection() as conn:
            for match in matches:
                try:
                    tenant_id = await fetch_val(
                        "SELECT tenant_id FROM projects WHERE id = $1", match.project_id
                    )

                    await conn.execute(
                        """
                        INSERT INTO project_engineer_matches (
                            id, tenant_id, project_id, engineer_id, matching_history_id,
                            match_score, confidence_score, skill_match_score, experience_match_score,
                            japanese_level_match_score, matched_skills, missing_skills,
                            matched_experiences, missing_experiences, match_reasons, concerns, status
                        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17)
                        ON CONFLICT (tenant_id, project_id, engineer_id) 
                        DO UPDATE SET
                            match_score = EXCLUDED.match_score,
                            confidence_score = EXCLUDED.confidence_score,
                            skill_match_score = EXCLUDED.skill_match_score,
                            experience_match_score = EXCLUDED.experience_match_score,
                            japanese_level_match_score = EXCLUDED.japanese_level_match_score,
                            matched_skills = EXCLUDED.matched_skills,
                            missing_skills = EXCLUDED.missing_skills,
                            matched_experiences = EXCLUDED.matched_experiences,
                            missing_experiences = EXCLUDED.missing_experiences,
                            match_reasons = EXCLUDED.match_reasons,
                            concerns = EXCLUDED.concerns,
                            matching_history_id = EXCLUDED.matching_history_id,
                            updated_at = NOW()
                        """,
                        match.id,
                        tenant_id,
                        match.project_id,
                        match.engineer_id,
                        matching_history_id,
                        match.match_score,
                        match.confidence_score,
                        match.skill_match_score,
                        match.experience_match_score,
                        match.japanese_level_match_score,
                        match.matched_skills,
                        match.missing_skills,
                        match.matched_experiences or [],  # ç®€åŒ–ç‰ˆå¯èƒ½ä¸ºç©º
                        match.missing_experiences or [],  # ç®€åŒ–ç‰ˆå¯èƒ½ä¸ºç©º
                        match.match_reasons,
                        match.concerns,
                        match.status,
                    )

                    saved_matches.append(match)

                except Exception as e:
                    logger.error(f"ä¿å­˜åŒ¹é…è®°å½•å¤±è´¥: {match.id}, é”™è¯¯: {str(e)}")
                    continue

        logger.info(f"æˆåŠŸä¿å­˜ {len(saved_matches)}/{len(matches)} ä¸ªåŒ¹é…è®°å½•")
        return saved_matches

    # ========== æ ¸å¿ƒåŒ¹é…è®¡ç®—æ–¹æ³• ==========

    async def _calculate_project_engineer_matches(
        self,
        project_info: Dict[str, Any],
        engineers: List[Dict[str, Any]],
        weights: Dict[str, float],
        max_matches: int,
        min_score: float,
        matching_history_id: UUID,
    ) -> List[MatchResult]:
        """
        ğŸ”¥ æ´¾é£ä¸“ç”¨æ¡ˆä»¶-ç®€å†åŒ¹é…è®¡ç®—
        """
        matches = []

        if not project_info.get("ai_match_embedding"):
            logger.warning(f"æ¡ˆä»¶ {project_info['id']} æ²¡æœ‰embeddingæ•°æ®")
            return matches

        # ğŸ”§ ä¿®å¤ï¼šè¿‡æ»¤æœ‰embeddingçš„å·¥ç¨‹å¸ˆ
        engineers_with_embedding = [e for e in engineers if e.get("ai_match_embedding")]

        if not engineers_with_embedding:
            logger.warning("æ²¡æœ‰å·¥ç¨‹å¸ˆæœ‰embeddingæ•°æ®")
            return matches

        logger.info(
            f"å¼€å§‹è®¡ç®—ç›¸ä¼¼åº¦ï¼Œé¡¹ç›®: {project_info.get('title', '')}, å€™é€‰ç®€å†: {len(engineers_with_embedding)}"
        )

        engineer_similarities = await self._calculate_similarities_batch(
            project_info["ai_match_embedding"],
            engineers_with_embedding,
            "engineers",
        )

        logger.info(f"è®¡ç®—äº† {len(engineer_similarities)} ä¸ªç›¸ä¼¼åº¦åˆ†æ•°")

        # ğŸ”§ ä¿®å¤ï¼šé™ä½æœ€å°åˆ†æ•°é˜ˆå€¼ï¼Œç¡®ä¿æœ‰ç»“æœè¿”å›
        effective_min_score = max(0, min(min_score, 0.1))  # æœ€ä½ä¸ä½äº0.1

        for engineer, similarity_score in engineer_similarities:
            try:
                similarity_score = self._validate_similarity_score(
                    similarity_score, f"å·¥ç¨‹å¸ˆ {engineer['id']}"
                )

                detailed_scores = self._calculate_detailed_match_scores(
                    project_info, engineer
                )

                final_score = self._calculate_weighted_score(
                    detailed_scores, weights, similarity_score
                )

                final_score = self._validate_similarity_score(
                    final_score, f"æœ€ç»ˆåˆ†æ•° {engineer['id']}"
                )

                # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æœ‰æ•ˆçš„æœ€å°åˆ†æ•°
                if final_score >= effective_min_score:
                    reasons, concerns = self._generate_match_analysis(
                        project_info, engineer, detailed_scores
                    )

                    match = MatchResult(
                        id=uuid4(),
                        project_id=project_info["id"],
                        engineer_id=engineer["id"],
                        match_score=round(final_score, 3),
                        confidence_score=round(
                            similarity_score * 0.4 + final_score * 0.6, 3
                        ),
                        skill_match_score=detailed_scores.get("skill_match"),
                        experience_match_score=detailed_scores.get("experience_match"),
                        japanese_level_match_score=detailed_scores.get(
                            "japanese_level_match"
                        ),
                        project_experience_match_score=None,  # ç®€åŒ–ç‰ˆä¸éœ€è¦
                        budget_match_score=None,  # ç®€åŒ–ç‰ˆä¸éœ€è¦
                        location_match_score=None,  # ç®€åŒ–ç‰ˆä¸éœ€è¦
                        matched_skills=detailed_scores.get("matched_skills", []),
                        missing_skills=detailed_scores.get("missing_skills", []),
                        matched_experiences=[],  # ç®€åŒ–ç‰ˆä¸éœ€è¦å¤æ‚ç»éªŒåŒ¹é…
                        missing_experiences=[],  # ç®€åŒ–ç‰ˆä¸éœ€è¦å¤æ‚ç»éªŒåŒ¹é…
                        project_experience_match=[],  # ç®€åŒ–ç‰ˆä¸éœ€è¦
                        missing_project_experience=[],  # ç®€åŒ–ç‰ˆä¸éœ€è¦
                        match_reasons=reasons,
                        concerns=concerns,
                        project_title=project_info.get("title"),
                        engineer_name=engineer.get("name"),
                        status="æœªä¿å­˜",
                        created_at=datetime.utcnow(),
                    )

                    matches.append(match)

            except Exception as e:
                logger.error(
                    f"è®¡ç®—åŒ¹é…å¤±è´¥ - æ¡ˆä»¶: {project_info['id']}, ç®€å†: {engineer['id']}, é”™è¯¯: {str(e)}"
                )
                continue

        matches.sort(key=lambda x: x.match_score, reverse=True)

        if matches:
            scores = [m.match_score for m in matches]
            logger.info(
                f"åˆ†æ•°åˆ†å¸ƒ: æœ€é«˜={max(scores):.3f}, æœ€ä½={min(scores):.3f}, å¹³å‡={np.mean(scores):.3f}"
            )
        else:
            logger.warning("æ²¡æœ‰ç”Ÿæˆä»»ä½•åŒ¹é…ç»“æœ")

        return matches[:max_matches]

    # ========== ä¿®å¤çš„ç®€å†åŒ¹é…æ¡ˆä»¶æ–¹æ³• ==========

    async def _calculate_engineer_project_matches(
        self,
        engineer_info: Dict[str, Any],
        projects: List[Dict[str, Any]],
        weights: Dict[str, float],
        max_matches: int,
        min_score: float,
        matching_history_id: UUID,
    ) -> List[MatchResult]:
        """
        ğŸ”¥ æ–°å¢ï¼šç®€å†åŒ¹é…æ¡ˆä»¶è®¡ç®—
        """
        matches = []

        if not engineer_info.get("ai_match_embedding"):
            logger.warning(f"ç®€å† {engineer_info['id']} æ²¡æœ‰embeddingæ•°æ®")
            return matches

        # è¿‡æ»¤æœ‰embeddingçš„é¡¹ç›®
        projects_with_embedding = [p for p in projects if p.get("ai_match_embedding")]

        if not projects_with_embedding:
            logger.warning("æ²¡æœ‰é¡¹ç›®æœ‰embeddingæ•°æ®")
            return matches

        logger.info(
            f"å¼€å§‹è®¡ç®—ç›¸ä¼¼åº¦ï¼Œç®€å†: {engineer_info.get('name', '')}, å€™é€‰é¡¹ç›®: {len(projects_with_embedding)}"
        )

        project_similarities = await self._calculate_similarities_batch(
            engineer_info["ai_match_embedding"],
            projects_with_embedding,
            "projects",
        )

        logger.info(f"è®¡ç®—äº† {len(project_similarities)} ä¸ªç›¸ä¼¼åº¦åˆ†æ•°")

        # é™ä½æœ€å°åˆ†æ•°é˜ˆå€¼
        effective_min_score = max(0, min(min_score, 0.1))

        for project, similarity_score in project_similarities:
            try:
                similarity_score = self._validate_similarity_score(
                    similarity_score, f"é¡¹ç›® {project['id']}"
                )

                # æ³¨æ„ï¼šè¿™é‡Œæ˜¯engineer_infoå’Œprojectçš„é¡ºåº
                detailed_scores = self._calculate_detailed_match_scores(
                    project, engineer_info
                )

                final_score = self._calculate_weighted_score(
                    detailed_scores, weights, similarity_score
                )

                final_score = self._validate_similarity_score(
                    final_score, f"æœ€ç»ˆåˆ†æ•° {project['id']}"
                )

                if final_score >= effective_min_score:
                    reasons, concerns = self._generate_match_analysis(
                        project, engineer_info, detailed_scores
                    )

                    match = MatchResult(
                        id=uuid4(),
                        project_id=project["id"],
                        engineer_id=engineer_info["id"],
                        match_score=round(final_score, 3),
                        confidence_score=round(
                            similarity_score * 0.4 + final_score * 0.6, 3
                        ),
                        skill_match_score=detailed_scores.get("skill_match"),
                        experience_match_score=detailed_scores.get("experience_match"),
                        japanese_level_match_score=detailed_scores.get(
                            "japanese_level_match"
                        ),
                        project_experience_match_score=None,
                        budget_match_score=None,
                        location_match_score=None,
                        matched_skills=detailed_scores.get("matched_skills", []),
                        missing_skills=detailed_scores.get("missing_skills", []),
                        matched_experiences=[],
                        missing_experiences=[],
                        project_experience_match=[],
                        missing_project_experience=[],
                        match_reasons=reasons,
                        concerns=concerns,
                        project_title=project.get("title"),
                        engineer_name=engineer_info.get("name"),
                        status="æœªä¿å­˜",
                        created_at=datetime.utcnow(),
                    )

                    matches.append(match)

            except Exception as e:
                logger.error(
                    f"è®¡ç®—åŒ¹é…å¤±è´¥ - ç®€å†: {engineer_info['id']}, é¡¹ç›®: {project['id']}, é”™è¯¯: {str(e)}"
                )
                continue

        matches.sort(key=lambda x: x.match_score, reverse=True)

        if matches:
            scores = [m.match_score for m in matches]
            logger.info(
                f"åˆ†æ•°åˆ†å¸ƒ: æœ€é«˜={max(scores):.3f}, æœ€ä½={min(scores):.3f}, å¹³å‡={np.mean(scores):.3f}"
            )

        return matches[:max_matches]

    # ========== ä¸»è¦APIæ–¹æ³• ==========

    async def match_project_to_engineers(
        self, request: ProjectToEngineersMatchRequest
    ) -> ProjectToEngineersResponse:
        """æ¡ˆä»¶åŒ¹é…ç®€å†ï¼ˆä¿®å¤ç‰ˆï¼‰"""
        start_time = time.time()

        try:
            logger.info(f"å¼€å§‹æ¡ˆä»¶åŒ¹é…ç®€å†: project_id={request.project_id}")

            matching_history = await self._create_matching_history(
                tenant_id=request.tenant_id,
                matching_type="project_to_engineers",
                trigger_type=request.trigger_type,
                executed_by=request.executed_by,
                project_ids=[request.project_id],
                filters=request.filters or {},
            )

            try:
                project_info = await self._get_project_info(
                    request.project_id, request.tenant_id
                )
                if not project_info:
                    raise ValueError(f"æ¡ˆä»¶ä¸å­˜åœ¨: {request.project_id}")

                candidate_engineers = await self._get_candidate_engineers(
                    request.tenant_id, request.filters or {}
                )

                logger.info(f"æ‰¾åˆ° {len(candidate_engineers)} ä¸ªå€™é€‰ç®€å†")

                matches = await self._calculate_project_engineer_matches(
                    project_info,
                    candidate_engineers,
                    request.weights or {},
                    request.max_matches,
                    request.min_score,
                    matching_history["id"],
                )

                saved_matches = await self._save_matches(
                    matches, matching_history["id"]
                )

                processing_time = int(time.time() - start_time)
                high_quality_matches = len(
                    [m for m in saved_matches if m.match_score >= 0.8]
                )

                await self._update_matching_history(
                    matching_history["id"],
                    execution_status="completed",
                    total_engineers_input=len(candidate_engineers),
                    total_matches_generated=len(saved_matches),
                    high_quality_matches=high_quality_matches,
                    processing_time_seconds=processing_time,
                    ai_config={
                        "weights": request.weights,
                        "model_version": self.model_version,
                        "algorithm_version": "dispatch_simplified_v1.0",  # æ ‡è®°ç®€åŒ–ç‰ˆ
                    },
                    engineer_ids=[e["id"] for e in candidate_engineers],
                )

                logger.info(f"æ¡ˆä»¶åŒ¹é…å®Œæˆ: ç”Ÿæˆ {len(saved_matches)} ä¸ªåŒ¹é…")

                return ProjectToEngineersResponse(
                    matching_history=MatchingHistoryResponse(**matching_history),
                    matches=saved_matches,
                    total_matches=len(saved_matches),
                    high_quality_matches=high_quality_matches,
                    processing_time_seconds=processing_time,
                    project_info=self._format_project_info(project_info),
                    matched_engineers=saved_matches,
                    recommendations=self._generate_project_recommendations(
                        project_info, saved_matches
                    ),
                    warnings=[],
                )

            except Exception as e:
                await self._update_matching_history(
                    matching_history["id"],
                    execution_status="failed",
                    error_message=str(e),
                )
                raise

        except Exception as e:
            logger.error(f"æ¡ˆä»¶åŒ¹é…ç®€å†å¤±è´¥: {str(e)}")
            raise Exception(f"åŒ¹é…å¤±è´¥: {str(e)}")

    async def match_engineer_to_projects(
        self, request: EngineerToProjectsMatchRequest
    ) -> EngineerToProjectsResponse:
        """ç®€å†åŒ¹é…æ¡ˆä»¶ï¼ˆæ–°å®ç°ï¼‰"""
        start_time = time.time()

        try:
            logger.info(f"å¼€å§‹ç®€å†åŒ¹é…æ¡ˆä»¶: engineer_id={request.engineer_id}")

            matching_history = await self._create_matching_history(
                tenant_id=request.tenant_id,
                matching_type="engineer_to_projects",
                trigger_type=request.trigger_type,
                executed_by=request.executed_by,
                engineer_ids=[request.engineer_id],
                filters=request.filters or {},
            )

            try:
                engineer_info = await self._get_engineer_info(
                    request.engineer_id, request.tenant_id
                )
                if not engineer_info:
                    raise ValueError(f"ç®€å†ä¸å­˜åœ¨: {request.engineer_id}")

                candidate_projects = await self._get_candidate_projects(
                    request.tenant_id, request.filters or {}
                )

                logger.info(f"æ‰¾åˆ° {len(candidate_projects)} ä¸ªå€™é€‰é¡¹ç›®")

                matches = await self._calculate_engineer_project_matches(
                    engineer_info,
                    candidate_projects,
                    request.weights or {},
                    request.max_matches,
                    request.min_score,
                    matching_history["id"],
                )

                saved_matches = await self._save_matches(
                    matches, matching_history["id"]
                )

                processing_time = int(time.time() - start_time)
                high_quality_matches = len(
                    [m for m in saved_matches if m.match_score >= 0.8]
                )

                await self._update_matching_history(
                    matching_history["id"],
                    execution_status="completed",
                    total_projects_input=len(candidate_projects),
                    total_matches_generated=len(saved_matches),
                    high_quality_matches=high_quality_matches,
                    processing_time_seconds=processing_time,
                    ai_config={
                        "weights": request.weights,
                        "model_version": self.model_version,
                        "algorithm_version": "dispatch_simplified_v1.0",
                    },
                    project_ids=[p["id"] for p in candidate_projects],
                )

                logger.info(f"ç®€å†åŒ¹é…å®Œæˆ: ç”Ÿæˆ {len(saved_matches)} ä¸ªåŒ¹é…")

                return EngineerToProjectsResponse(
                    matching_history=MatchingHistoryResponse(**matching_history),
                    matches=saved_matches,
                    total_matches=len(saved_matches),
                    high_quality_matches=high_quality_matches,
                    processing_time_seconds=processing_time,
                    engineer_info=self._format_engineer_info(engineer_info),
                    matched_projects=saved_matches,
                    recommendations=self._generate_engineer_recommendations(
                        engineer_info, saved_matches
                    ),
                    warnings=[],
                )

            except Exception as e:
                await self._update_matching_history(
                    matching_history["id"],
                    execution_status="failed",
                    error_message=str(e),
                )
                raise

        except Exception as e:
            logger.error(f"ç®€å†åŒ¹é…æ¡ˆä»¶å¤±è´¥: {str(e)}")
            raise Exception(f"åŒ¹é…å¤±è´¥: {str(e)}")

    async def bulk_matching(self, request: BulkMatchingRequest) -> BulkMatchingResponse:
        """æ‰¹é‡åŒ¹é…ï¼ˆæ–°å®ç°ï¼‰"""
        start_time = time.time()

        try:
            logger.info("å¼€å§‹æ‰¹é‡åŒ¹é…")

            matching_history = await self._create_matching_history(
                tenant_id=request.tenant_id,
                matching_type="bulk_matching",
                trigger_type=request.trigger_type,
                executed_by=request.executed_by,
                project_ids=request.project_ids,
                engineer_ids=request.engineer_ids,
                filters=request.filters or {},
            )

            try:
                # è·å–é¡¹ç›®å’Œç®€å†æ•°æ®
                if request.project_ids:
                    candidate_projects = []
                    for project_id in request.project_ids:
                        project = await self._get_project_info(
                            project_id, request.tenant_id
                        )
                        if project:
                            candidate_projects.append(project)
                else:
                    candidate_projects = await self._get_candidate_projects(
                        request.tenant_id, request.filters or {}
                    )

                if request.engineer_ids:
                    candidate_engineers = []
                    for engineer_id in request.engineer_ids:
                        engineer = await self._get_engineer_info(
                            engineer_id, request.tenant_id
                        )
                        if engineer:
                            candidate_engineers.append(engineer)
                else:
                    candidate_engineers = await self._get_candidate_engineers(
                        request.tenant_id, request.filters or {}
                    )

                logger.info(
                    f"æ‰¹é‡åŒ¹é…ï¼š{len(candidate_projects)} ä¸ªé¡¹ç›® Ã— {len(candidate_engineers)} ä¸ªç®€å†"
                )

                all_matches = []
                top_matches_by_project = {}

                # é™åˆ¶å¤„ç†æ•°é‡ä»¥é¿å…è¶…æ—¶
                max_projects = min(len(candidate_projects), 10)  # æœ€å¤šå¤„ç†10ä¸ªé¡¹ç›®

                for i, project in enumerate(candidate_projects[:max_projects]):
                    logger.info(
                        f"å¤„ç†é¡¹ç›® {i+1}/{max_projects}: {project.get('title', '')}"
                    )

                    project_matches = await self._calculate_project_engineer_matches(
                        project,
                        candidate_engineers,
                        {
                            "skill_match": 0.5,
                            "experience_match": 0.3,
                            "japanese_level_match": 0.2,
                        },
                        request.max_matches,
                        request.min_score,
                        matching_history["id"],
                    )

                    if project_matches:
                        all_matches.extend(project_matches)
                        top_matches_by_project[str(project["id"])] = project_matches[
                            :3
                        ]  # å‰3ä¸ª

                # ä¿å­˜æ‰€æœ‰åŒ¹é…
                saved_matches = await self._save_matches(
                    all_matches, matching_history["id"]
                )

                processing_time = int(time.time() - start_time)
                high_quality_matches = len(
                    [m for m in saved_matches if m.match_score >= 0.8]
                )

                await self._update_matching_history(
                    matching_history["id"],
                    execution_status="completed",
                    total_projects_input=len(candidate_projects),
                    total_engineers_input=len(candidate_engineers),
                    total_matches_generated=len(saved_matches),
                    high_quality_matches=high_quality_matches,
                    processing_time_seconds=processing_time,
                    ai_config={
                        "batch_size": request.batch_size,
                        "model_version": self.model_version,
                        "algorithm_version": "dispatch_simplified_v1.0",
                    },
                    project_ids=[p["id"] for p in candidate_projects],
                    engineer_ids=[e["id"] for e in candidate_engineers],
                )

                logger.info(f"æ‰¹é‡åŒ¹é…å®Œæˆ: ç”Ÿæˆ {len(saved_matches)} ä¸ªåŒ¹é…")

                return BulkMatchingResponse(
                    matching_history=MatchingHistoryResponse(**matching_history),
                    matches=saved_matches,
                    total_matches=len(saved_matches),
                    high_quality_matches=high_quality_matches,
                    processing_time_seconds=processing_time,
                    batch_summary={
                        "total_projects": len(candidate_projects),
                        "total_engineers": len(candidate_engineers),
                        "processed_projects": max_projects,
                        "average_match_score": (
                            np.mean([m.match_score for m in saved_matches])
                            if saved_matches
                            else 0
                        ),
                    },
                    top_matches_by_project=top_matches_by_project,
                    top_matches_by_engineer={},  # ç®€åŒ–ç‰ˆæš‚ä¸å®ç°
                    recommendations=["æ‰¹é‡åŒ¹é…å·²å®Œæˆï¼Œå»ºè®®æŸ¥çœ‹é«˜åˆ†åŒ¹é…é¡¹ç›®"],
                    warnings=(
                        [] if len(saved_matches) > 0 else ["æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„åŒ¹é…"]
                    ),
                )

            except Exception as e:
                await self._update_matching_history(
                    matching_history["id"],
                    execution_status="failed",
                    error_message=str(e),
                )
                raise

        except Exception as e:
            logger.error(f"æ‰¹é‡åŒ¹é…å¤±è´¥: {str(e)}")
            raise Exception(f"æ‰¹é‡åŒ¹é…å¤±è´¥: {str(e)}")

    # ========== æ–°å¢çš„è¾…åŠ©æ–¹æ³• ==========

    async def _get_engineer_info(
        self, engineer_id: UUID, tenant_id: UUID
    ) -> Optional[Dict[str, Any]]:
        """è·å–ç®€å†ä¿¡æ¯"""
        query = """
        SELECT * FROM engineers 
        WHERE id = $1 AND tenant_id = $2 AND is_active = true
        """
        return await fetch_one(query, engineer_id, tenant_id)

    async def _get_candidate_projects(
        self, tenant_id: UUID, filters: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """è·å–å€™é€‰é¡¹ç›®"""
        base_query = """
        SELECT * FROM projects 
        WHERE tenant_id = $1 AND is_active = true
        """
        params = [tenant_id]
        conditions = []

        if "status" in filters:
            conditions.append(f"status = ANY(${len(params) + 1})")
            params.append(filters["status"])

        if "skills" in filters:
            conditions.append(f"skills && ${len(params) + 1}")
            params.append(filters["skills"])

        if conditions:
            base_query += " AND " + " AND ".join(conditions)

        base_query += " AND ai_match_embedding IS NOT NULL"
        base_query += " ORDER BY created_at DESC LIMIT 1000"

        return await fetch_all(base_query, *params)

    def _format_engineer_info(self, engineer: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–ç®€å†ä¿¡æ¯"""
        return {
            "id": str(engineer["id"]),
            "name": engineer.get("name", ""),
            "skills": engineer.get("skills", []),
            "experience": engineer.get("experience", ""),
            "japanese_level": engineer.get("japanese_level", ""),
            "current_status": engineer.get("current_status", ""),
        }

    def _generate_engineer_recommendations(
        self, engineer: Dict[str, Any], matches: List[MatchResult]
    ) -> List[str]:
        """ç”Ÿæˆç®€å†æ¨è"""
        recommendations = []

        if not matches:
            recommendations.append("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„é¡¹ç›®ï¼Œå»ºè®®æ‰©å±•æŠ€èƒ½èŒƒå›´")
        elif len([m for m in matches if m.match_score >= 0.8]) == 0:
            recommendations.append("é«˜è´¨é‡åŒ¹é…è¾ƒå°‘ï¼Œå»ºè®®æå‡æŠ€èƒ½æ°´å¹³æˆ–è€ƒè™‘æ›´å¤šé¡¹ç›®ç±»å‹")

        if len(matches) >= 5:
            recommendations.append("æœ‰å¤šä¸ªåŒ¹é…é¡¹ç›®ï¼Œå»ºè®®ä¼˜å…ˆå…³æ³¨å‰3ä¸ªé«˜åˆ†é¡¹ç›®")

        return recommendations

    # ========== ä¿æŒåŸæœ‰çš„è¾…åŠ©æ–¹æ³•ï¼ˆæœªä¿®æ”¹éƒ¨åˆ†ï¼‰ ==========

    async def _create_matching_history(
        self,
        tenant_id: UUID,
        matching_type: str,
        trigger_type: str,
        executed_by: Optional[UUID] = None,
        project_ids: Optional[List[UUID]] = None,
        engineer_ids: Optional[List[UUID]] = None,
        filters: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """åˆ›å»ºåŒ¹é…å†å²è®°å½•"""
        async with get_db_connection() as conn:
            filters_json = json.dumps(filters or {})
            project_ids_list = project_ids or []
            engineer_ids_list = engineer_ids or []
            ai_config_json = json.dumps({})
            statistics_json = json.dumps({})

            history_id = await conn.fetchval(
                """
                INSERT INTO ai_matching_history (
                    tenant_id, executed_by, matching_type, trigger_type,
                    project_ids, engineer_ids, filters, ai_model_version,
                    ai_config, statistics
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
                RETURNING id
                """,
                tenant_id,
                executed_by,
                matching_type,
                trigger_type,
                project_ids_list,
                engineer_ids_list,
                filters_json,
                self.model_version,
                ai_config_json,
                statistics_json,
            )

            history_data = await conn.fetchrow(
                "SELECT * FROM ai_matching_history WHERE id = $1", history_id
            )

            return self._format_matching_history(dict(history_data))

    async def _update_matching_history(
        self,
        history_id: UUID,
        execution_status: str,
        total_projects_input: int = 0,
        total_engineers_input: int = 0,
        total_matches_generated: int = 0,
        high_quality_matches: int = 0,
        processing_time_seconds: Optional[int] = None,
        error_message: Optional[str] = None,
        ai_config: Optional[Dict[str, Any]] = None,
        project_ids: Optional[List[UUID]] = None,
        engineer_ids: Optional[List[UUID]] = None,
    ):
        """æ›´æ–°åŒ¹é…å†å²"""
        async with get_db_connection() as conn:
            statistics = {
                "total_projects_input": total_projects_input,
                "total_engineers_input": total_engineers_input,
                "total_matches_generated": total_matches_generated,
                "high_quality_matches": high_quality_matches,
                "processing_time_seconds": processing_time_seconds,
            }

            ai_config_json = json.dumps(ai_config or {})
            statistics_json = json.dumps(statistics)

            await conn.execute(
                """
                UPDATE ai_matching_history SET
                    execution_status = $2,
                    completed_at = $3,
                    total_projects_input = $4,
                    total_engineers_input = $5,
                    total_matches_generated = $6,
                    high_quality_matches = $7,
                    processing_time_seconds = $8,
                    error_message = $9,
                    ai_config = $10,
                    statistics = $11,
                    project_ids = COALESCE($12, project_ids),
                    engineer_ids = COALESCE($13, engineer_ids)
                WHERE id = $1
                """,
                history_id,
                execution_status,
                (
                    datetime.utcnow()
                    if execution_status in ["completed", "failed"]
                    else None
                ),
                total_projects_input,
                total_engineers_input,
                total_matches_generated,
                high_quality_matches,
                processing_time_seconds,
                error_message,
                ai_config_json,
                statistics_json,
                project_ids,
                engineer_ids,
            )

    async def _get_project_info(
        self, project_id: UUID, tenant_id: UUID
    ) -> Optional[Dict[str, Any]]:
        """è·å–æ¡ˆä»¶ä¿¡æ¯"""
        query = """
        SELECT * FROM projects 
        WHERE id = $1 AND tenant_id = $2 AND is_active = true
        """
        return await fetch_one(query, project_id, tenant_id)

    async def _get_candidate_engineers(
        self, tenant_id: UUID, filters: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """è·å–å€™é€‰ç®€å†"""
        base_query = """
        SELECT * FROM engineers 
        WHERE tenant_id = $1 AND is_active = true
        """
        params = [tenant_id]
        conditions = []

        if "japanese_level" in filters:
            conditions.append(f"japanese_level = ANY(${len(params) + 1})")
            params.append(filters["japanese_level"])

        if "current_status" in filters:
            conditions.append(f"current_status = ANY(${len(params) + 1})")
            params.append(filters["current_status"])

        if "skills" in filters:
            conditions.append(f"skills && ${len(params) + 1}")
            params.append(filters["skills"])

        if conditions:
            base_query += " AND " + " AND ".join(conditions)

        base_query += " AND ai_match_embedding IS NOT NULL"
        base_query += " ORDER BY created_at DESC LIMIT 1000"

        return await fetch_all(base_query, *params)

    def _format_project_info(self, project: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–æ¡ˆä»¶ä¿¡æ¯"""
        return {
            "id": str(project["id"]),
            "title": project.get("title", ""),
            "company": project.get("client_company", ""),
            "skills": project.get("skills", []),
            "experience": project.get("experience", ""),
            "japanese_level": project.get("japanese_level", ""),
            "status": project.get("status", ""),
        }

    def _generate_project_recommendations(
        self, project: Dict[str, Any], matches: List[MatchResult]
    ) -> List[str]:
        """ç”Ÿæˆæ¡ˆä»¶æ¨è"""
        recommendations = []

        if not matches:
            recommendations.append("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„ç®€å†ï¼Œå»ºè®®è°ƒæ•´éœ€æ±‚æ¡ä»¶")
        elif len([m for m in matches if m.match_score >= 0.8]) == 0:
            recommendations.append("é«˜è´¨é‡åŒ¹é…è¾ƒå°‘ï¼Œå»ºè®®æ”¾å®½æŠ€èƒ½è¦æ±‚æˆ–é™ä½å¹´é™è¦æ±‚")

        if len(matches) >= 5:
            recommendations.append("å»ºè®®ä¼˜å…ˆè”ç³»å‰3åé«˜åˆ†å€™é€‰äºº")

        return recommendations

    # ========== å†å²æŸ¥è¯¢æ–¹æ³• ==========

    async def get_matching_history(
        self, tenant_id: UUID, history_id: Optional[UUID] = None, limit: int = 20
    ) -> List[MatchingHistoryResponse]:
        """è·å–åŒ¹é…å†å²"""
        try:
            if history_id:
                query = """
                SELECT * FROM ai_matching_history 
                WHERE id = $1 AND tenant_id = $2
                """
                history_data = await fetch_one(query, history_id, tenant_id)
                if not history_data:
                    return []

                formatted_data = self._format_matching_history(dict(history_data))
                return [MatchingHistoryResponse(**formatted_data)]
            else:
                query = """
                SELECT * FROM ai_matching_history 
                WHERE tenant_id = $1
                ORDER BY started_at DESC
                LIMIT $2
                """
                histories = await fetch_all(query, tenant_id, limit)

                formatted_histories = []
                for history in histories:
                    formatted_data = self._format_matching_history(dict(history))
                    formatted_histories.append(
                        MatchingHistoryResponse(**formatted_data)
                    )

                return formatted_histories

        except Exception as e:
            logger.error(f"è·å–åŒ¹é…å†å²å¤±è´¥: {str(e)}")
            return []

    async def get_matches_by_history(
        self, history_id: UUID, tenant_id: UUID, limit: int = 100
    ) -> List[MatchResult]:
        """æ ¹æ®å†å²IDè·å–åŒ¹é…ç»“æœ"""
        try:
            query = """
            SELECT m.*, p.title as project_title, e.name as engineer_name
            FROM project_engineer_matches m
            LEFT JOIN projects p ON m.project_id = p.id
            LEFT JOIN engineers e ON m.engineer_id = e.id
            WHERE m.matching_history_id = $1 AND m.tenant_id = $2
            ORDER BY m.match_score DESC
            LIMIT $3
            """

            matches_data = await fetch_all(query, history_id, tenant_id, limit)

            matches = []
            for data in matches_data:
                match = MatchResult(
                    id=data["id"],
                    project_id=data["project_id"],
                    engineer_id=data["engineer_id"],
                    match_score=(
                        float(data["match_score"]) if data["match_score"] else 0.0
                    ),
                    confidence_score=(
                        float(data["confidence_score"])
                        if data["confidence_score"]
                        else 0.0
                    ),
                    skill_match_score=(
                        float(data["skill_match_score"])
                        if data["skill_match_score"]
                        else None
                    ),
                    experience_match_score=(
                        float(data["experience_match_score"])
                        if data["experience_match_score"]
                        else None
                    ),
                    japanese_level_match_score=(
                        float(data["japanese_level_match_score"])
                        if data["japanese_level_match_score"]
                        else None
                    ),
                    project_experience_match_score=None,
                    budget_match_score=None,
                    location_match_score=None,
                    matched_skills=data["matched_skills"] or [],
                    missing_skills=data["missing_skills"] or [],
                    matched_experiences=data["matched_experiences"] or [],
                    missing_experiences=data["missing_experiences"] or [],
                    project_experience_match=[],
                    missing_project_experience=[],
                    match_reasons=data["match_reasons"] or [],
                    concerns=data["concerns"] or [],
                    project_title=data["project_title"],
                    engineer_name=data["engineer_name"],
                    status=data["status"],
                    created_at=data["created_at"],
                )
                matches.append(match)

            return matches

        except Exception as e:
            logger.error(f"æ ¹æ®å†å²è·å–åŒ¹é…ç»“æœå¤±è´¥: {str(e)}")
            return []

    async def update_match_status(
        self,
        match_id: UUID,
        tenant_id: UUID,
        status: str,
        comment: Optional[str] = None,
        reviewed_by: Optional[UUID] = None,
    ) -> bool:
        """æ›´æ–°åŒ¹é…çŠ¶æ€"""
        try:
            async with get_db_connection() as conn:
                await conn.execute(
                    """
                    UPDATE project_engineer_matches 
                    SET status = $1, comment = $2, reviewed_by = $3, reviewed_at = $4, updated_at = $5
                    WHERE id = $6 AND tenant_id = $7
                    """,
                    status,
                    comment,
                    reviewed_by,
                    datetime.utcnow(),
                    datetime.utcnow(),
                    match_id,
                    tenant_id,
                )

            logger.info(f"åŒ¹é…çŠ¶æ€æ›´æ–°æˆåŠŸ: {match_id} -> {status}")
            return True

        except Exception as e:
            logger.error(f"æ›´æ–°åŒ¹é…çŠ¶æ€å¤±è´¥: {str(e)}")
            return False
