# -*- coding: utf-8 -*-
"""
AiMatchingSendMail ç®€å†æå–å™¨è°ƒè¯•è„šæœ¬
ç”¨äºè¯Šæ–­ arrival_year_japan å’Œ experience å­—æ®µè¿”å› null çš„é—®é¢˜
"""

import asyncio
import sys
import traceback
import pandas as pd
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

try:
    from app.services.resume_parser_service import ResumeParserService
except ImportError as e:
    print(f"âŒ æ— æ³•å¯¼å…¥ResumeParserService: {e}")
    sys.exit(1)


async def debug_extraction():
    """è°ƒè¯•æå–å™¨é—®é¢˜"""

    print("=== AiMatchingSendMail ç®€å†æå–å™¨è°ƒè¯• ===\n")

    # åˆå§‹åŒ–æœåŠ¡
    try:
        parser = ResumeParserService()
        print("âœ… æå–å™¨æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æå–å™¨æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        traceback.print_exc()
        return

    # æµ‹è¯•å¯¼å…¥çŠ¶æ€
    print("\n=== æ£€æŸ¥å¯¼å…¥çŠ¶æ€ ===")

    try:
        # æ£€æŸ¥å„ä¸ªæå–å™¨çš„çŠ¶æ€
        extractors = [
            ("å§“å", parser.name_extractor),
            ("æ¥æ—¥å¹´ä»½", parser.arrival_year_extractor),
            ("ç»éªŒ", parser.experience_extractor),
            ("å¹´é¾„", parser.age_extractor),
            ("æŠ€èƒ½", parser.skills_extractor),
        ]

        for name, extractor in extractors:
            if hasattr(extractor, "__class__"):
                print(f"âœ… {name}æå–å™¨: {extractor.__class__.__name__}")

                # æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹å®šæ–¹æ³•
                methods_to_check = [
                    "_extract_from_arrival_labels",
                    "_extract_from_experience_labels",
                    "_extract_from_years_expression",
                    "_search_experience_value",
                ]

                for method in methods_to_check:
                    if hasattr(extractor, method):
                        print(f"   - æœ‰ {method} æ–¹æ³•")

            else:
                print(f"âŒ {name}æå–å™¨: æœªæ­£ç¡®åˆå§‹åŒ–")

    except Exception as e:
        print(f"âŒ æ£€æŸ¥æå–å™¨çŠ¶æ€æ—¶å‡ºé”™: {e}")
        traceback.print_exc()

    # æµ‹è¯•å…³é”®è¯å¯¼å…¥
    print("\n=== æ£€æŸ¥å…³é”®è¯å¯¼å…¥ ===")

    try:
        # å°è¯•å„ç§å¯¼å…¥è·¯å¾„
        import_paths = [
            "base.constants",
            "app.base.constants",
            "app.utils.resume_constants",
            "extractors.constants",
        ]

        keywords_found = False

        for path in import_paths:
            try:
                if path == "base.constants":
                    from base.constants import KEYWORDS
                elif path == "app.base.constants":
                    from app.base.constants import KEYWORDS
                elif path == "app.utils.resume_constants":
                    from app.utils.resume_constants import VALID_SKILLS as KEYWORDS
                elif path == "extractors.constants":
                    from extractors.constants import KEYWORDS

                print(f"âœ… æˆåŠŸä» {path} å¯¼å…¥å…³é”®è¯")

                if isinstance(KEYWORDS, dict):
                    arrival_keys = KEYWORDS.get("arrival", [])
                    experience_keys = KEYWORDS.get("experience", [])

                    print(
                        f"   - arrival å…³é”®è¯ ({len(arrival_keys)}ä¸ª): {arrival_keys[:3]}..."
                    )
                    print(
                        f"   - experience å…³é”®è¯ ({len(experience_keys)}ä¸ª): {experience_keys[:3]}..."
                    )
                else:
                    print(f"   - å¯¼å…¥çš„ä¸æ˜¯å­—å…¸ç±»å‹: {type(KEYWORDS)}")

                keywords_found = True
                break

            except ImportError:
                print(f"âŒ æ— æ³•ä» {path} å¯¼å…¥å…³é”®è¯")
            except Exception as e:
                print(f"âŒ ä» {path} å¯¼å…¥æ—¶å‡ºé”™: {e}")

        if not keywords_found:
            print("âŒ æ‰€æœ‰å¯¼å…¥è·¯å¾„éƒ½å¤±è´¥äº†ï¼è¿™æ˜¯ä¸»è¦é—®é¢˜åŸå› ã€‚")

    except Exception as e:
        print(f"âŒ æ£€æŸ¥å…³é”®è¯å¯¼å…¥æ—¶å‡ºé”™: {e}")

    # æµ‹è¯•åŸºç±»å¯¼å…¥
    print("\n=== æ£€æŸ¥åŸºç±»å¯¼å…¥ ===")

    base_import_paths = [
        "base.base_extractor",
        "app.base.base_extractor",
        "extractors.base_extractor",
    ]

    for path in base_import_paths:
        try:
            if path == "base.base_extractor":
                from base.base_extractor import BaseExtractor
            elif path == "app.base.base_extractor":
                from app.base.base_extractor import BaseExtractor
            elif path == "extractors.base_extractor":
                from extractors.base_extractor import BaseExtractor

            print(f"âœ… æˆåŠŸä» {path} å¯¼å…¥ BaseExtractor")
            print(
                f"   - åŸºç±»æ–¹æ³•: {[m for m in dir(BaseExtractor) if not m.startswith('_')]}"
            )
            break

        except ImportError:
            print(f"âŒ æ— æ³•ä» {path} å¯¼å…¥ BaseExtractor")
        except Exception as e:
            print(f"âŒ ä» {path} å¯¼å…¥æ—¶å‡ºé”™: {e}")

    # å¦‚æœæœ‰æµ‹è¯•æ–‡ä»¶ï¼Œè¿›è¡Œå®é™…æå–æµ‹è¯•
    print("\n=== æ–‡ä»¶æå–æµ‹è¯• ===")
    test_file = input("è¯·è¾“å…¥æµ‹è¯•æ–‡ä»¶è·¯å¾„ï¼ˆç•™ç©ºè·³è¿‡æµ‹è¯•ï¼‰: ").strip()

    if test_file and Path(test_file).exists():
        print(f"\næµ‹è¯•æ–‡ä»¶æå–: {test_file}")

        try:
            result = await parser.parse_resume(test_file)

            print(f"âœ… è§£æå®Œæˆï¼ŒæˆåŠŸ: {result.get('success', False)}")
            print(f"è§£æè€—æ—¶: {result.get('parse_time', 0):.3f}ç§’")

            if result.get("success"):
                data = result.get("data", {})

                # é‡ç‚¹æ£€æŸ¥é—®é¢˜å­—æ®µ
                problem_fields = ["arrival_year_japan", "experience"]

                print("\nğŸ” é‡ç‚¹å­—æ®µæ£€æŸ¥:")
                for field in problem_fields:
                    value = data.get(field)
                    value_type = type(value).__name__
                    value_str = f"'{value}'" if isinstance(value, str) else str(value)

                    if value is None:
                        print(
                            f"  âŒ {field}: {value_str} (ç±»å‹: {value_type}) - é—®é¢˜ï¼åº”è¯¥æœ‰å€¼"
                        )
                    else:
                        print(f"  âœ… {field}: {value_str} (ç±»å‹: {value_type}) - æ­£å¸¸")

                print(f"\nğŸ“‹ å®Œæ•´æå–ç»“æœ:")
                for key, value in data.items():
                    indicator = (
                        "âŒ" if value is None and key in problem_fields else "âœ…"
                    )
                    print(f"  {indicator} {key}: {value}")

            else:
                error_msg = result.get("error", "Unknown error")
                print(f"âŒ è§£æå¤±è´¥: {error_msg}")

        except Exception as e:
            print(f"âŒ è§£æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            traceback.print_exc()

    elif test_file:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")

    print("\n=== è°ƒè¯•å®Œæˆ ===")


def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®è¿›è¡Œç®€å•éªŒè¯"""

    print("\n=== åˆ›å»ºæµ‹è¯•æ•°æ®éªŒè¯ ===")

    # åˆ›å»ºæ¨¡æ‹Ÿçš„Excelæ•°æ®
    test_data = [
        {
            "df": pd.DataFrame(
                {
                    "A": ["æ°å", "æ¥æ—¥å¹´", "å®Ÿå‹™çµŒé¨“", "å¹´é½¢", "æ€§åˆ¥"],
                    "B": ["ã‚¨ãƒ³", "2016", "4å¹´", "27", "ç”·æ€§"],
                    "C": [None, None, None, None, None],
                }
            ),
            "sheet_name": "test_sheet",
        }
    ]

    print("ğŸ“‹ æµ‹è¯•æ•°æ®:")
    print(test_data[0]["df"])

    # æµ‹è¯•å„ä¸ªæå–å™¨
    try:
        parser = ResumeParserService()

        # æµ‹è¯•æ¥æ—¥å¹´ä»½æå–
        print("\nğŸ” æµ‹è¯•æ¥æ—¥å¹´ä»½æå–:")
        try:
            arrival_result = parser.arrival_year_extractor.extract(test_data, None)
            print(f"ç»“æœ: {arrival_result}")
            if arrival_result == "2016":
                print("âœ… æ¥æ—¥å¹´ä»½æå–æ­£å¸¸")
            else:
                print("âŒ æ¥æ—¥å¹´ä»½æå–å¼‚å¸¸")
        except Exception as e:
            print(f"âŒ æ¥æ—¥å¹´ä»½æå–å¤±è´¥: {e}")
            traceback.print_exc()

        # æµ‹è¯•ç»éªŒæå–
        print("\nğŸ” æµ‹è¯•ç»éªŒæå–:")
        try:
            experience_result = parser.experience_extractor.extract(test_data)
            print(f"ç»“æœ: {experience_result}")
            if experience_result == "4å¹´":
                print("âœ… ç»éªŒæå–æ­£å¸¸")
            else:
                print("âŒ ç»éªŒæå–å¼‚å¸¸")
        except Exception as e:
            print(f"âŒ ç»éªŒæå–å¤±è´¥: {e}")
            traceback.print_exc()

    except Exception as e:
        print(f"âŒ åˆ›å»ºè§£æå™¨å¤±è´¥: {e}")


def create_fix_constants_file():
    """åˆ›å»ºä¿®å¤ç”¨çš„å¸¸é‡æ–‡ä»¶"""

    print("\n=== åˆ›å»ºä¿®å¤æ–‡ä»¶ ===")

    constants_content = '''# -*- coding: utf-8 -*-
"""å¸¸é‡å®šä¹‰ - ä¿®å¤ç‰ˆæœ¬"""

# å…³é”®è¯å®šä¹‰
KEYWORDS = {
    "name": ["æ°å", "æ° å", "åå‰", "ãƒ•ãƒªã‚¬ãƒŠ", "Name", "åã€€å‰", "å§“å"],
    "age": ["å¹´é½¢", "å¹´é¾„", "å¹´ä»¤", "æ­³", "æ‰", "Age", "å¹´ã€€é½¢", "ç”Ÿå¹´æœˆ", "æº€"],
    "gender": ["æ€§åˆ¥", "æ€§åˆ«", "Gender", "æ€§ã€€åˆ¥"],
    "nationality": ["å›½ç±", "å‡ºèº«å›½", "å‡ºèº«åœ°", "Nationality", "å›½ã€€ç±"],
    "experience": [
        "çµŒé¨“å¹´æ•°",
        "å®Ÿå‹™çµŒé¨“",
        "é–‹ç™ºçµŒé¨“", 
        "ã‚½ãƒ•ãƒˆé–¢é€£æ¥­å‹™çµŒé¨“å¹´æ•°",
        "ITçµŒé¨“",
        "æ¥­å‹™çµŒé¨“",
        "çµŒé¨“",
        "å®Ÿå‹™å¹´æ•°",
        "Experience",
        "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢çµŒé¨“",
        "çµŒé¨“å¹´æœˆ",
        "è·æ­´",
        "ITçµŒé¨“å¹´æ•°",
        "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚½ãƒ•ãƒˆã‚¦ã‚¨ã‚¢é–¢é€£æ¥­å‹™",
    ],
    "arrival": [
        "æ¥æ—¥",
        "æ¸¡æ—¥",
        "å…¥å›½", 
        "æ—¥æœ¬æ»åœ¨å¹´æ•°",
        "æ»åœ¨å¹´æ•°",
        "åœ¨æ—¥å¹´æ•°",
        "æ¥æ—¥å¹´",
        "æ¥æ—¥æ™‚æœŸ",
        "æ¥æ—¥å¹´æœˆ",
        "æ¥æ—¥å¹´åº¦",
    ],
    "japanese": [
        "æ—¥æœ¬èª",
        "æ—¥èª",
        "JLPT", 
        "æ—¥æœ¬èªèƒ½åŠ›",
        "èªå­¦åŠ›",
        "è¨€èªèƒ½åŠ›",
        "æ—¥æœ¬èªãƒ¬ãƒ™ãƒ«",
        "Japanese",
    ],
    "education": ["å­¦æ­´", "å­¦æ ¡", "å¤§å­¦", "å’æ¥­", "å°‚é–€å­¦æ ¡", "é«˜æ ¡", "æœ€çµ‚å­¦æ­´"],
    "skills": [
        "æŠ€è¡“",
        "ã‚¹ã‚­ãƒ«",
        "è¨€èª",
        "DB",
        "OS", 
        "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯",
        "ãƒ„ãƒ¼ãƒ«",
        "Skills",
        "å¼€å‘è¯­è¨€",
        "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª",
        "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹",
        "é–‹ç™ºç’°å¢ƒ",
        "æŠ€è¡“çµŒé¨“",
    ],
}

# æœ‰æ•ˆçš„å›½ç±åˆ—è¡¨
VALID_NATIONALITIES = [
    "ä¸­å›½", "æ—¥æœ¬", "éŸ“å›½", "ãƒ™ãƒˆãƒŠãƒ ", "ãƒ•ã‚£ãƒªãƒ”ãƒ³", "ã‚¤ãƒ³ãƒ‰", "ãƒãƒ‘ãƒ¼ãƒ«",
    "ã‚¢ãƒ¡ãƒªã‚«", "ãƒ–ãƒ©ã‚¸ãƒ«", "å°æ¹¾", "ã‚¿ã‚¤", "ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢", "ãƒãƒ³ã‚°ãƒ©ãƒ‡ã‚·ãƒ¥",
    "ã‚¹ãƒªãƒ©ãƒ³ã‚«", "ãƒŸãƒ£ãƒ³ãƒãƒ¼", "ã‚«ãƒ³ãƒœã‚¸ã‚¢", "ãƒ©ã‚ªã‚¹", "ãƒ¢ãƒ³ã‚´ãƒ«",
]

# æœ‰æ•ˆæŠ€èƒ½åˆ—è¡¨
VALID_SKILLS = [
    # ç¼–ç¨‹è¯­è¨€
    "Java", "Python", "JavaScript", "C#", "C++", "C", "Go", "Ruby", "PHP",
    "TypeScript", "Swift", "Kotlin", "Rust", "Scala", "R", "VB.NET", "VB",
    "VBA", "COBOL", "Perl", "Shell", "Bash", "PowerShell",
    # å‰ç«¯æŠ€æœ¯
    "HTML", "CSS", "React", "Vue", "Angular", "jQuery", "Bootstrap", 
    "Sass", "Less", "Webpack", "Next.js", "React Native", "Flutter",
    # åç«¯æ¡†æ¶
    "Spring", "SpringBoot", "Spring Boot", "Django", "Flask", "FastAPI",
    "Express", "Node.js", "Rails", "Laravel", ".NET", "ASP.NET", "Struts",
    "Hibernate", "MyBatis", "Mybatis", "JSP", "Servlet",
    # æ•°æ®åº“
    "MySQL", "PostgreSQL", "Oracle", "SQL Server", "MongoDB", "Redis",
    "Elasticsearch", "SQLite", "DB2", "Access", "Firebase",
    # äº‘æœåŠ¡å’Œå·¥å…·
    "AWS", "Azure", "GCP", "Docker", "Kubernetes", "Git", "SVN", "Jenkins",
    "Eclipse", "IntelliJ IDEA", "Visual Studio", "VS Code",
    # æ“ä½œç³»ç»Ÿ
    "Windows", "Linux", "Unix", "macOS", "Ubuntu", "CentOS", "Red Hat",
    # å…¶ä»–æŠ€æœ¯
    "REST", "GraphQL", "SOAP", "WebSocket", "Nginx", "Apache", "Tomcat",
]
'''

    try:
        # åˆ›å»ºç›®å½•ç»“æ„
        base_dir = Path("app/base")
        base_dir.mkdir(parents=True, exist_ok=True)

        # å†™å…¥å¸¸é‡æ–‡ä»¶
        constants_file = base_dir / "constants.py"
        with open(constants_file, "w", encoding="utf-8") as f:
            f.write(constants_content)

        # åˆ›å»º__init__.py
        init_content = """from .constants import KEYWORDS, VALID_SKILLS, VALID_NATIONALITIES

__all__ = ["KEYWORDS", "VALID_SKILLS", "VALID_NATIONALITIES"]
"""

        init_file = base_dir / "__init__.py"
        with open(init_file, "w", encoding="utf-8") as f:
            f.write(init_content)

        print(f"âœ… å·²åˆ›å»ºä¿®å¤æ–‡ä»¶:")
        print(f"   - {constants_file}")
        print(f"   - {init_file}")

        # åˆ›å»ºåŸºç±»æ–‡ä»¶
        base_extractor_content = '''# -*- coding: utf-8 -*-
"""åŸºç¡€æå–å™¨ç±»"""

from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
import pandas as pd


class BaseExtractor(ABC):
    """æ‰€æœ‰æå–å™¨çš„åŸºç±»"""

    def __init__(self):
        """åˆå§‹åŒ–åŸºç¡€æå–å™¨"""
        # å…¨è§’è½¬åŠè§’çš„è½¬æ¢è¡¨
        self.trans_table = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789")

    @abstractmethod
    def extract(self, all_data: List[Dict[str, Any]]) -> Any:
        """æå–ä¿¡æ¯çš„æŠ½è±¡æ–¹æ³•"""
        pass

    def has_nearby_keyword(
        self, df: pd.DataFrame, row: int, col: int, keywords: List[str], radius: int = 5
    ) -> bool:
        """æ£€æŸ¥é™„è¿‘æ˜¯å¦æœ‰å…³é”®è¯"""
        for r in range(max(0, row - radius), min(len(df), row + radius + 1)):
            for c in range(max(0, col - radius), min(len(df.columns), col + radius + 1)):
                cell = df.iloc[r, c]
                if pd.notna(cell) and any(k in str(cell) for k in keywords):
                    return True
        return False

    def get_context_score(
        self, df: pd.DataFrame, row: int, col: int, context_keywords: List[str]
    ) -> float:
        """è®¡ç®—ä¸Šä¸‹æ–‡è¯„åˆ†"""
        score = 0.0
        for r in range(max(0, row - 3), min(len(df), row + 4)):
            for c in range(max(0, col - 5), min(len(df.columns), col + 6)):
                cell = df.iloc[r, c]
                if pd.notna(cell):
                    cell_str = str(cell)
                    for keyword in context_keywords:
                        if keyword in cell_str:
                            score += 1.0
        return score
'''

        base_extractor_file = base_dir / "base_extractor.py"
        with open(base_extractor_file, "w", encoding="utf-8") as f:
            f.write(base_extractor_content)

        print(f"   - {base_extractor_file}")

        print("\nğŸ’¡ åˆ›å»ºå®Œæˆåï¼Œè¯·ä¿®æ”¹æå–å™¨æ–‡ä»¶ä¸­çš„å¯¼å…¥è¯­å¥:")
        print("   å°† 'from base.constants import KEYWORDS'")
        print("   æ”¹ä¸º 'from app.base.constants import KEYWORDS'")

    except Exception as e:
        print(f"âŒ åˆ›å»ºä¿®å¤æ–‡ä»¶å¤±è´¥: {e}")
        traceback.print_exc()


def show_import_fix_guide():
    """æ˜¾ç¤ºå¯¼å…¥ä¿®å¤æŒ‡å—"""

    print("\n=== å¯¼å…¥é—®é¢˜ä¿®å¤æŒ‡å— ===")

    print("\nğŸ“‹ éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶å’Œå¯¼å…¥è¯­å¥:")

    files_to_fix = [
        "app/services/extractors/arrival_year_extractor.py",
        "app/services/extractors/experience_extractor.py",
        "app/services/extractors/age_extractor.py",
        "app/services/extractors/birthdate_extractor.py",
        "app/services/extractors/name_extractor.py",
        "app/services/extractors/skills_extractor.py",
        # æ·»åŠ å…¶ä»–æå–å™¨æ–‡ä»¶
    ]

    print("\nğŸ”§ ä¿®æ”¹æ­¥éª¤:")
    for i, file_path in enumerate(files_to_fix, 1):
        print(f"\n{i}. ç¼–è¾‘ {file_path}")
        print("   æ‰¾åˆ°:")
        print("     from base.constants import KEYWORDS")
        print("     from base.base_extractor import BaseExtractor")
        print("   æ›¿æ¢ä¸º:")
        print("     from app.base.constants import KEYWORDS")
        print("     from app.base.base_extractor import BaseExtractor")

    print("\nğŸ“ æ‰¹é‡æ›¿æ¢å‘½ä»¤ (Linux/Mac):")
    print(
        "find app/services/extractors/ -name '*.py' -exec sed -i 's/from base\\.constants/from app.base.constants/g' {} \\;"
    )
    print(
        "find app/services/extractors/ -name '*.py' -exec sed -i 's/from base\\.base_extractor/from app.base.base_extractor/g' {} \\;"
    )

    print("\nğŸ“ æ‰¹é‡æ›¿æ¢å‘½ä»¤ (Windows PowerShell):")
    print(
        "Get-ChildItem app/services/extractors/*.py | ForEach-Object { (Get-Content $_) -replace 'from base\\.constants', 'from app.base.constants' | Set-Content $_ }"
    )
    print(
        "Get-ChildItem app/services/extractors/*.py | ForEach-Object { (Get-Content $_) -replace 'from base\\.base_extractor', 'from app.base.base_extractor' | Set-Content $_ }"
    )


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ AiMatchingSendMail æå–å™¨è°ƒè¯•å·¥å…·")
    print("=" * 50)
    print("1. è¿è¡Œå®Œæ•´è°ƒè¯•æ£€æŸ¥")
    print("2. åˆ›å»ºæµ‹è¯•æ•°æ®éªŒè¯")
    print("3. åˆ›å»ºä¿®å¤ç”¨å¸¸é‡æ–‡ä»¶")
    print("4. æ˜¾ç¤ºå¯¼å…¥ä¿®å¤æŒ‡å—")
    print("5. é€€å‡º")

    while True:
        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1-5): ").strip()

        if choice == "1":
            asyncio.run(debug_extraction())
        elif choice == "2":
            create_test_data()
        elif choice == "3":
            create_fix_constants_file()
        elif choice == "4":
            show_import_fix_guide()
        elif choice == "5":
            print("ğŸ‘‹ é€€å‡ºè°ƒè¯•å·¥å…·")
            break
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-5")


if __name__ == "__main__":
    main()
