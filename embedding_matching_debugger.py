#!/usr/bin/env python3
# fixed_embedding_matching_debugger.py - ä¿®å¤pgvectorå…¼å®¹æ€§é—®é¢˜
import asyncio
import sys
from pathlib import Path
import numpy as np
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app.database import fetch_one, fetch_all
from app.services.ai_matching_service import AIMatchingService
from app.schemas.ai_matching_schemas import ProjectToEngineersMatchRequest
from uuid import UUID


class FixedEmbeddingMatchingDebugger:
    """ä¿®å¤ç‰ˆï¼šè¯Šæ–­ç›¸åŒembeddingæ— æ³•åŒ¹é…çš„é—®é¢˜"""

    def __init__(self):
        self.tenant_id = "33723dd6-cf28-4dab-975c-f883f5389d04"
        self.matching_service = AIMatchingService()

    async def check_pgvector_setup(self):
        """æ£€æŸ¥pgvectoræ‰©å±•å’Œè®¾ç½®"""
        print("ğŸ” æ£€æŸ¥pgvectoræ‰©å±•...")

        try:
            # æ£€æŸ¥pgvectoræ‰©å±•
            extension_check = await fetch_one(
                """
                SELECT * FROM pg_extension WHERE extname = 'vector'
            """
            )

            if extension_check:
                print("âœ… pgvectoræ‰©å±•å·²å®‰è£…")
            else:
                print("âŒ pgvectoræ‰©å±•æœªå®‰è£…")
                return False

            # æ£€æŸ¥vectorç›¸å…³å‡½æ•°
            functions_check = await fetch_all(
                """
                SELECT proname FROM pg_proc 
                WHERE proname IN ('vector_dims', 'cosine_distance', 'inner_product')
            """
            )

            available_functions = [f["proname"] for f in functions_check]
            print(f"å¯ç”¨å‡½æ•°: {available_functions}")

            # æµ‹è¯•vectoræ“ä½œ
            test_result = await fetch_one(
                """
                SELECT '[1,2,3]'::vector as test_vector
            """
            )

            if test_result:
                print("âœ… vectorç±»å‹å·¥ä½œæ­£å¸¸")

            return True

        except Exception as e:
            print(f"âŒ pgvectoræ£€æŸ¥å¤±è´¥: {str(e)}")
            return False

    async def check_database_consistency_fixed(self):
        """ä¿®å¤ç‰ˆï¼šæ£€æŸ¥æ•°æ®åº“ä¸€è‡´æ€§ï¼ˆå…¼å®¹pgvectorï¼‰"""
        print("\nğŸ” æ£€æŸ¥æ•°æ®åº“ä¸€è‡´æ€§")
        print("=" * 60)

        try:
            # ä¿®å¤ç‰ˆé¡¹ç›®ç»Ÿè®¡ï¼ˆå…¼å®¹vectorç±»å‹ï¼‰
            project_stats = await fetch_one(
                """
                SELECT 
                    COUNT(*) as total,
                    COUNT(ai_match_embedding) as with_embedding,
                    -- ä½¿ç”¨vector_dimså‡½æ•°è·å–å‘é‡ç»´åº¦
                    (SELECT vector_dims(ai_match_embedding) 
                     FROM projects 
                     WHERE tenant_id = $1 AND ai_match_embedding IS NOT NULL 
                     LIMIT 1) as embedding_dims
                FROM projects 
                WHERE tenant_id = $1 AND is_active = true
            """,
                self.tenant_id,
            )

            # ä¿®å¤ç‰ˆç®€å†ç»Ÿè®¡
            engineer_stats = await fetch_one(
                """
                SELECT 
                    COUNT(*) as total,
                    COUNT(ai_match_embedding) as with_embedding,
                    -- ä½¿ç”¨vector_dimså‡½æ•°è·å–å‘é‡ç»´åº¦
                    (SELECT vector_dims(ai_match_embedding) 
                     FROM engineers 
                     WHERE tenant_id = $1 AND ai_match_embedding IS NOT NULL 
                     LIMIT 1) as embedding_dims
                FROM engineers 
                WHERE tenant_id = $1 AND is_active = true
            """,
                self.tenant_id,
            )

            print(f"é¡¹ç›®ç»Ÿè®¡:")
            print(f"  æ€»æ•°: {project_stats['total']}")
            print(f"  æœ‰embedding: {project_stats['with_embedding']}")
            print(f"  embeddingç»´åº¦: {project_stats['embedding_dims']}")

            print(f"\nç®€å†ç»Ÿè®¡:")
            print(f"  æ€»æ•°: {engineer_stats['total']}")
            print(f"  æœ‰embedding: {engineer_stats['with_embedding']}")
            print(f"  embeddingç»´åº¦: {engineer_stats['embedding_dims']}")

            # æ£€æŸ¥åŒ¹é…å†å²
            match_history = await fetch_one(
                """
                SELECT 
                    COUNT(*) as total_history,
                    COUNT(CASE WHEN execution_status = 'completed' THEN 1 END) as completed,
                    COUNT(CASE WHEN execution_status = 'failed' THEN 1 END) as failed
                FROM ai_matching_history 
                WHERE tenant_id = $1
            """,
                self.tenant_id,
            )

            print(f"\nåŒ¹é…å†å²:")
            print(f"  æ€»å†å²è®°å½•: {match_history['total_history']}")
            print(f"  æˆåŠŸå®Œæˆ: {match_history['completed']}")
            print(f"  å¤±è´¥: {match_history['failed']}")

            # æ£€æŸ¥å·²ä¿å­˜çš„åŒ¹é…
            saved_matches = await fetch_one(
                """
                SELECT 
                    COUNT(*) as total_matches,
                    AVG(match_score) as avg_score,
                    COUNT(CASE WHEN match_score >= 0.8 THEN 1 END) as high_quality
                FROM project_engineer_matches 
                WHERE tenant_id = $1 AND is_active = true
            """,
                self.tenant_id,
            )

            print(f"\nå·²ä¿å­˜åŒ¹é…:")
            print(f"  æ€»åŒ¹é…æ•°: {saved_matches['total_matches']}")
            print(
                f"  å¹³å‡åˆ†æ•°: {saved_matches['avg_score']:.4f}"
                if saved_matches["avg_score"]
                else "  å¹³å‡åˆ†æ•°: 0"
            )
            print(f"  é«˜è´¨é‡åŒ¹é…: {saved_matches['high_quality']}")

            return True

        except Exception as e:
            print(f"âŒ æ•°æ®åº“ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {str(e)}")
            import traceback

            print(f"è¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}")
            return False

    async def find_similar_embeddings_fixed(self):
        """ä¿®å¤ç‰ˆï¼šæŸ¥æ‰¾ç›¸ä¼¼çš„embeddingï¼ˆä½¿ç”¨pgvectoræŸ¥è¯¢ï¼‰"""
        print("\nğŸ” æŸ¥æ‰¾ç›¸ä¼¼çš„embedding...")

        try:
            # è·å–ä¸€ä¸ªæµ‹è¯•é¡¹ç›®
            test_project = await fetch_one(
                """
                SELECT id, title, ai_match_embedding, skills, experience, japanese_level
                FROM projects 
                WHERE tenant_id = $1 AND is_active = true AND ai_match_embedding IS NOT NULL
                ORDER BY created_at DESC LIMIT 1
            """,
                self.tenant_id,
            )

            if not test_project:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•é¡¹ç›®")
                return []

            print(f"æµ‹è¯•é¡¹ç›®: {test_project['title']}")

            # ä½¿ç”¨pgvectoræŸ¥æ‰¾æœ€ç›¸ä¼¼çš„ç®€å†
            similar_engineers = await fetch_all(
                """
                SELECT 
                    id, name, ai_match_embedding,
                    skills, experience, japanese_level,
                    ai_match_embedding <#> $1 as cosine_distance,
                    1 - (ai_match_embedding <#> $1) as cosine_similarity
                FROM engineers 
                WHERE tenant_id = $2 AND is_active = true AND ai_match_embedding IS NOT NULL
                ORDER BY ai_match_embedding <#> $1 ASC
                LIMIT 10
            """,
                test_project["ai_match_embedding"],
                self.tenant_id,
            )

            print(f"æ‰¾åˆ° {len(similar_engineers)} ä¸ªç›¸ä¼¼ç®€å†")

            # åˆ†æå‰3ä¸ªæœ€ç›¸ä¼¼çš„
            for i, engineer in enumerate(similar_engineers[:3]):
                similarity = engineer["cosine_similarity"]
                distance = engineer["cosine_distance"]

                print(f"\n=== ç›¸ä¼¼ç®€å† {i+1} ===")
                print(f"ç®€å†: {engineer['name']}")
                print(f"ä½™å¼¦è·ç¦»: {distance:.6f}")
                print(f"ä½™å¼¦ç›¸ä¼¼åº¦: {similarity:.6f}")
                print(f"é¡¹ç›®æŠ€èƒ½: {test_project['skills']}")
                print(f"ç®€å†æŠ€èƒ½: {engineer['skills']}")
                print(f"é¡¹ç›®ç»éªŒ: {test_project['experience']}")
                print(f"ç®€å†ç»éªŒ: {engineer['experience']}")
                print(f"é¡¹ç›®æ—¥è¯­: {test_project['japanese_level']}")
                print(f"ç®€å†æ—¥è¯­: {engineer['japanese_level']}")

                # æµ‹è¯•è¿™å¯¹æ•°æ®çš„åŒ¹é…æƒ…å†µ
                await self.debug_specific_pair_fixed(test_project, engineer)

            return similar_engineers

        except Exception as e:
            print(f"âŒ æŸ¥æ‰¾ç›¸ä¼¼embeddingå¤±è´¥: {str(e)}")
            import traceback

            print(f"è¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}")
            return []

    async def debug_specific_pair_fixed(self, project, engineer):
        """ä¿®å¤ç‰ˆï¼šè°ƒè¯•ç‰¹å®šçš„é¡¹ç›®-ç®€å†å¯¹"""
        print(f"\nğŸ” è°ƒè¯•åŒ¹é…è¿‡ç¨‹:")

        try:
            # 1. éªŒè¯pgvectorç›¸ä¼¼åº¦è®¡ç®—
            print("1. éªŒè¯pgvectorç›¸ä¼¼åº¦è®¡ç®—...")

            pgvector_result = await fetch_one(
                """
                SELECT 
                    ai_match_embedding <#> $1 as distance,
                    1 - (ai_match_embedding <#> $1) as similarity
                FROM engineers 
                WHERE id = $2
            """,
                project["ai_match_embedding"],
                engineer["id"],
            )

            if pgvector_result:
                distance = pgvector_result["distance"]
                similarity = pgvector_result["similarity"]
                print(f"   pgvectorè·ç¦»: {distance:.6f}")
                print(f"   pgvectorç›¸ä¼¼åº¦: {similarity:.6f}")
            else:
                print("   âŒ pgvectoræŸ¥è¯¢å¤±è´¥")
                return

            # 2. æµ‹è¯•è¯¦ç»†åˆ†æ•°è®¡ç®—
            print("2. æµ‹è¯•è¯¦ç»†åˆ†æ•°è®¡ç®—...")
            detailed_scores = self.matching_service._calculate_detailed_match_scores(
                project, engineer
            )

            for key, value in detailed_scores.items():
                if isinstance(value, (int, float)):
                    print(f"   {key}: {value:.4f}")
                else:
                    print(f"   {key}: {value}")

            # 3. æµ‹è¯•æƒé‡åˆ†æ•°è®¡ç®—
            print("3. æµ‹è¯•æƒé‡åˆ†æ•°è®¡ç®—...")
            weights = {
                "skill_match": 0.5,
                "experience_match": 0.3,
                "japanese_level_match": 0.2,
            }

            final_score = self.matching_service._calculate_weighted_score(
                detailed_scores, weights, similarity
            )

            print(f"   è¯­ä¹‰ç›¸ä¼¼åº¦: {similarity:.4f}")
            print(f"   æœ€ç»ˆåˆ†æ•°: {final_score:.4f}")

            # 4. åˆ†æä¸ºä»€ä¹ˆå¯èƒ½åŒ¹é…ä¸ä¸Š
            print("4. åŒ¹é…å¤±è´¥åŸå› åˆ†æ...")

            # è®¡ç®—æ¯ä¸ªç»´åº¦å¯¹æœ€ç»ˆåˆ†æ•°çš„è´¡çŒ®
            skill_contribution = (
                detailed_scores.get("skill_match", 0) * weights["skill_match"]
            )
            exp_contribution = (
                detailed_scores.get("experience_match", 0) * weights["experience_match"]
            )
            jp_contribution = (
                detailed_scores.get("japanese_level_match", 0)
                * weights["japanese_level_match"]
            )

            base_score = skill_contribution + exp_contribution + jp_contribution
            semantic_contribution = similarity * 0.3
            structural_contribution = base_score * 0.7

            print(
                f"   æŠ€èƒ½è´¡çŒ®: {skill_contribution:.4f} (æƒé‡{weights['skill_match']})"
            )
            print(
                f"   ç»éªŒè´¡çŒ®: {exp_contribution:.4f} (æƒé‡{weights['experience_match']})"
            )
            print(
                f"   æ—¥è¯­è´¡çŒ®: {jp_contribution:.4f} (æƒé‡{weights['japanese_level_match']})"
            )
            print(f"   ç»“æ„åŒ–æ€»åˆ†: {base_score:.4f}")
            print(f"   è¯­ä¹‰è´¡çŒ®: {semantic_contribution:.4f} (æƒé‡0.3)")
            print(f"   ç»“æ„åŒ–è´¡çŒ®: {structural_contribution:.4f} (æƒé‡0.7)")
            print(f"   æœ€ç»ˆåˆ†æ•°: {semantic_contribution + structural_contribution:.4f}")

            # åˆ¤æ–­æ˜¯å¦ä¼šè¢«è¿‡æ»¤
            common_thresholds = [0.0, 0.1, 0.3, 0.5, 0.6, 0.7, 0.8]
            print(f"   ä¸åŒé—¨æ§›ä¸‹æ˜¯å¦é€šè¿‡:")
            for threshold in common_thresholds:
                passed = final_score >= threshold
                status = "âœ…" if passed else "âŒ"
                print(f"     é—¨æ§›{threshold}: {status}")

        except Exception as e:
            print(f"âŒ è°ƒè¯•è¿‡ç¨‹å‡ºé”™: {str(e)}")
            import traceback

            print(f"è¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}")

    async def test_direct_matching_fixed(self):
        """ä¿®å¤ç‰ˆï¼šç›´æ¥æµ‹è¯•åŒ¹é…åŠŸèƒ½"""
        print("\nğŸ¯ ç›´æ¥æµ‹è¯•åŒ¹é…åŠŸèƒ½")
        print("=" * 60)

        # è·å–æµ‹è¯•æ•°æ®
        project = await fetch_one(
            """
            SELECT * FROM projects 
            WHERE tenant_id = $1 AND is_active = true AND ai_match_embedding IS NOT NULL
            ORDER BY created_at DESC LIMIT 1
        """,
            self.tenant_id,
        )

        if not project:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•é¡¹ç›®")
            return

        print(f"æµ‹è¯•é¡¹ç›®: {project['title']}")

        # æµ‹è¯•ä¸åŒçš„é…ç½®
        test_configs = [
            {
                "name": "é›¶é—¨æ§›æµ‹è¯•",
                "min_score": 0.0,
                "weights": {
                    "skill_match": 0.5,
                    "experience_match": 0.3,
                    "japanese_level_match": 0.2,
                },
            },
            {
                "name": "è¯­ä¹‰ä¼˜å…ˆæµ‹è¯•",
                "min_score": 0.1,
                "weights": {
                    "skill_match": 0.1,
                    "experience_match": 0.1,
                    "japanese_level_match": 0.05,
                },
            },
            {
                "name": "æ ‡å‡†é…ç½®æµ‹è¯•",
                "min_score": 0.6,
                "weights": {
                    "skill_match": 0.5,
                    "experience_match": 0.3,
                    "japanese_level_match": 0.2,
                },
            },
        ]

        for config in test_configs:
            print(f"\nğŸ§ª {config['name']}:")
            print(f"   æœ€å°åˆ†æ•°: {config['min_score']}")
            print(f"   æƒé‡é…ç½®: {config['weights']}")

            try:
                # åˆ›å»ºåŒ¹é…è¯·æ±‚
                request = ProjectToEngineersMatchRequest(
                    tenant_id=UUID(self.tenant_id),
                    project_id=project["id"],
                    max_matches=10,
                    min_score=config["min_score"],
                    executed_by=None,
                    matching_type="project_to_engineers",
                    trigger_type="debug",
                    weights=config["weights"],
                    filters={},
                )

                result = await self.matching_service.match_project_to_engineers(request)

                print(f"   âœ… åŒ¹é…å®Œæˆ:")
                print(f"   æ€»åŒ¹é…æ•°: {result.total_matches}")
                print(f"   é«˜è´¨é‡åŒ¹é…: {result.high_quality_matches}")
                print(f"   å¤„ç†æ—¶é—´: {result.processing_time_seconds}ç§’")

                if result.matches:
                    print(f"   å‰3ä¸ªåŒ¹é…ç»“æœ:")
                    for i, match in enumerate(result.matches[:3], 1):
                        print(f"   {i}. {match.engineer_name}: {match.match_score:.4f}")
                        print(f"      æŠ€èƒ½: {match.skill_match_score:.4f}")
                        print(f"      ç»éªŒ: {match.experience_match_score:.4f}")
                        print(f"      æ—¥è¯­: {match.japanese_level_match_score:.4f}")
                else:
                    print("   âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒ¹é…")

            except Exception as e:
                print(f"   âŒ æµ‹è¯•å¤±è´¥: {str(e)}")

    async def generate_api_test_commands(self):
        """ç”ŸæˆAPIæµ‹è¯•å‘½ä»¤"""
        print("\nğŸ“‹ ç”ŸæˆAPIæµ‹è¯•å‘½ä»¤")
        print("=" * 60)

        # è·å–æµ‹è¯•é¡¹ç›®ID
        project = await fetch_one(
            """
            SELECT id, title FROM projects 
            WHERE tenant_id = $1 AND is_active = true AND ai_match_embedding IS NOT NULL
            ORDER BY created_at DESC LIMIT 1
        """,
            self.tenant_id,
        )

        if not project:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•é¡¹ç›®")
            return

        project_id = str(project["id"])
        print(f"æµ‹è¯•é¡¹ç›®: {project['title']} ({project_id})")

        # é›¶é—¨æ§›é…ç½®
        zero_threshold_config = {
            "tenant_id": self.tenant_id,
            "project_id": project_id,
            "max_matches": 20,
            "min_score": 0.0,
            "executed_by": None,
            "matching_type": "project_to_engineers",
            "trigger_type": "api_test",
            "weights": {
                "skill_match": 0.5,
                "experience_match": 0.3,
                "japanese_level_match": 0.2,
            },
            "filters": {},
        }

        # è¯­ä¹‰ä¼˜å…ˆé…ç½®
        semantic_first_config = {
            "tenant_id": self.tenant_id,
            "project_id": project_id,
            "max_matches": 20,
            "min_score": 0.0,
            "executed_by": None,
            "matching_type": "project_to_engineers",
            "trigger_type": "api_test",
            "weights": {
                "skill_match": 0.1,
                "experience_match": 0.1,
                "japanese_level_match": 0.05,
            },
            "filters": {},
        }

        import json

        print(f"\n1. é›¶é—¨æ§›æµ‹è¯• (curl):")
        print(
            f"curl -X POST 'http://localhost:8000/api/v1/ai-matching/project-to-engineers' \\"
        )
        print(f"     -H 'Content-Type: application/json' \\")
        print(f"     -d '{json.dumps(zero_threshold_config)}'")

        print(f"\n2. è¯­ä¹‰ä¼˜å…ˆæµ‹è¯• (curl):")
        print(
            f"curl -X POST 'http://localhost:8000/api/v1/ai-matching/project-to-engineers' \\"
        )
        print(f"     -H 'Content-Type: application/json' \\")
        print(f"     -d '{json.dumps(semantic_first_config)}'")

        print(f"\n3. Python requestsæµ‹è¯•:")
        python_code = f"""
import requests
import json

# é›¶é—¨æ§›é…ç½®
config = {json.dumps(zero_threshold_config, indent=4)}

response = requests.post(
    "http://localhost:8000/api/v1/ai-matching/project-to-engineers",
    json=config
)

print(f"çŠ¶æ€ç : {{response.status_code}}")
if response.status_code == 200:
    result = response.json()
    print(f"åŒ¹é…æ•°: {{result.get('total_matches', 0)}}")
    if result.get('matches'):
        print("å‰5ä¸ªåŒ¹é…:")
        for i, match in enumerate(result['matches'][:5], 1):
            print(f"{{i}}. {{match['engineer_name']}}: {{match['match_score']:.4f}}")
else:
    print(f"é”™è¯¯: {{response.text}}")
"""
        print(python_code)

    async def run_full_diagnosis_fixed(self):
        """è¿è¡Œå®Œæ•´è¯Šæ–­ï¼ˆä¿®å¤ç‰ˆï¼‰"""
        print("ğŸ¥ AIåŒ¹é…é—®é¢˜è¯Šæ–­å·¥å…· (ä¿®å¤ç‰ˆ)")
        print("=" * 80)

        try:
            # 1. æ£€æŸ¥pgvectorè®¾ç½®
            pgvector_ok = await self.check_pgvector_setup()
            if not pgvector_ok:
                print("âŒ pgvectorè®¾ç½®æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“é…ç½®")
                return

            # 2. æ£€æŸ¥æ•°æ®åº“ä¸€è‡´æ€§
            db_ok = await self.check_database_consistency_fixed()
            if not db_ok:
                print("âŒ æ•°æ®åº“ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥")
                return

            # 3. æŸ¥æ‰¾ç›¸ä¼¼embedding
            similar_pairs = await self.find_similar_embeddings_fixed()

            # 4. ç›´æ¥æµ‹è¯•åŒ¹é…
            await self.test_direct_matching_fixed()

            # 5. ç”ŸæˆAPIæµ‹è¯•å‘½ä»¤
            await self.generate_api_test_commands()

            # 6. ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
            self.generate_diagnosis_report_fixed(similar_pairs)

        except Exception as e:
            print(f"âŒ è¯Šæ–­è¿‡ç¨‹å‡ºé”™: {str(e)}")
            import traceback

            print(f"è¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}")

    def generate_diagnosis_report_fixed(self, similar_pairs):
        """ç”Ÿæˆè¯Šæ–­æŠ¥å‘Šï¼ˆä¿®å¤ç‰ˆï¼‰"""
        print("\n" + "=" * 80)
        print("ğŸ“Š è¯Šæ–­æŠ¥å‘Š")
        print("=" * 80)

        print(f"ğŸ” å‘ç° {len(similar_pairs)} ä¸ªç›¸ä¼¼ç®€å†")

        if similar_pairs:
            high_similarity_count = len(
                [p for p in similar_pairs if p["cosine_similarity"] > 0.9]
            )
            print(f"ğŸ¯ é«˜ç›¸ä¼¼åº¦ (>0.9): {high_similarity_count} ä¸ª")

            print("\nğŸ” é—®é¢˜è¯Šæ–­:")
            print("1. âœ… pgvectoræ‰©å±•å·¥ä½œæ­£å¸¸")
            print("2. âœ… embeddingæ•°æ®å­˜åœ¨")
            print("3. âœ… ç›¸ä¼¼åº¦è®¡ç®—æ­£å¸¸")

            if high_similarity_count > 0:
                print("4. âš ï¸  æœ‰é«˜ç›¸ä¼¼åº¦æ•°æ®ä½†å¯èƒ½åŒ¹é…å¤±è´¥")
                print("   åŸå› åˆ†æ:")
                print("   - ç»“æ„åŒ–åŒ¹é…åˆ†æ•°ä½ï¼ˆæŠ€èƒ½ã€ç»éªŒã€æ—¥è¯­ï¼‰")
                print("   - æƒé‡åˆ†é…ï¼š70%ç»“æ„åŒ– + 30%è¯­ä¹‰")
                print("   - æœ€å°åˆ†æ•°é—¨æ§›è¿‡é«˜")
            else:
                print("4. â„¹ï¸  ç›¸ä¼¼åº¦æ™®éè¾ƒä½ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡")

        print("\nğŸ’¡ è§£å†³å»ºè®®:")
        print("1. ç«‹å³å¯è¡Œ:")
        print("   - ä½¿ç”¨é›¶é—¨æ§›æµ‹è¯• (min_score: 0.0)")
        print("   - è°ƒæ•´æƒé‡ï¼Œé™ä½ç»“æ„åŒ–åŒ¹é…æƒé‡")
        print("   - ä½¿ç”¨è¯­ä¹‰ä¼˜å…ˆé…ç½®")

        print("\n2. é•¿æœŸä¼˜åŒ–:")
        print("   - æ”¹è¿›ç»“æ„åŒ–åŒ¹é…ç®—æ³•")
        print("   - ä¼˜åŒ–æƒé‡åˆ†é…ç­–ç•¥")
        print("   - å¢åŠ æ•°æ®è´¨é‡æ£€æŸ¥")

        print("\nğŸ› ï¸ ä¸‹ä¸€æ­¥æ“ä½œ:")
        print("1. ä½¿ç”¨ä¸Šé¢çš„APIæµ‹è¯•å‘½ä»¤éªŒè¯")
        print("2. æ£€æŸ¥å…·ä½“çš„ç»“æ„åŒ–åŒ¹é…åˆ†æ•°")
        print("3. è€ƒè™‘è°ƒæ•´åŒ¹é…ç®—æ³•å‚æ•°")


async def main():
    """ä¸»å‡½æ•°"""
    debugger = FixedEmbeddingMatchingDebugger()
    await debugger.run_full_diagnosis_fixed()


if __name__ == "__main__":
    asyncio.run(main())
