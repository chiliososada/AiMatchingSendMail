# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆè°ƒè¯•è„šæœ¬ - æ·±åº¦åˆ†æä¸ºä»€ä¹ˆ arrival_year_japan å’Œ experience è¿”å› None
"""

import asyncio
import sys
import traceback
import pandas as pd
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

try:
    from app.services.resume_parser_service import ResumeParserService
except ImportError as e:
    print(f"âŒ æ— æ³•å¯¼å…¥ResumeParserService: {e}")
    sys.exit(1)


async def deep_debug_extraction(test_file_path: str):
    """æ·±åº¦è°ƒè¯•æå–è¿‡ç¨‹"""

    print("=== æ·±åº¦è°ƒè¯•æå–è¿‡ç¨‹ ===\n")

    if not Path(test_file_path).exists():
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file_path}")
        return

    # åˆå§‹åŒ–æœåŠ¡
    parser = ResumeParserService()

    # 1. å…ˆæ£€æŸ¥æå–å™¨çš„å…³é”®è¯çŠ¶æ€
    print("ğŸ” æ£€æŸ¥æå–å™¨å…³é”®è¯çŠ¶æ€:")

    # æ£€æŸ¥ arrival_year_extractor
    arrival_extractor = parser.arrival_year_extractor
    print(f"\nğŸ“ æ¥æ—¥å¹´ä»½æå–å™¨: {arrival_extractor.__class__.__name__}")

    # å°è¯•è®¿é—®å…³é”®è¯
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰KEYWORDSå±æ€§æˆ–ç›¸å…³å¯¼å…¥
        if hasattr(arrival_extractor, "KEYWORDS"):
            print(f"   âœ… æå–å™¨æœ‰ KEYWORDS å±æ€§")
        else:
            print(f"   âŒ æå–å™¨æ²¡æœ‰ KEYWORDS å±æ€§")

        # æ£€æŸ¥æ¨¡å—çº§åˆ«çš„KEYWORDS
        import inspect

        module = inspect.getmodule(arrival_extractor)
        if hasattr(module, "KEYWORDS"):
            keywords = getattr(module, "KEYWORDS")
            arrival_keywords = keywords.get("arrival", [])
            print(f"   âœ… æ¨¡å—æœ‰ KEYWORDSï¼Œarrivalå…³é”®è¯: {arrival_keywords[:3]}...")
        else:
            print(f"   âŒ æ¨¡å—æ²¡æœ‰ KEYWORDS")

    except Exception as e:
        print(f"   âŒ æ£€æŸ¥å…³é”®è¯æ—¶å‡ºé”™: {e}")

    # æ£€æŸ¥ experience_extractor
    experience_extractor = parser.experience_extractor
    print(f"\nğŸ“ ç»éªŒæå–å™¨: {experience_extractor.__class__.__name__}")

    try:
        module = inspect.getmodule(experience_extractor)
        if hasattr(module, "KEYWORDS"):
            keywords = getattr(module, "KEYWORDS")
            experience_keywords = keywords.get("experience", [])
            print(
                f"   âœ… æ¨¡å—æœ‰ KEYWORDSï¼Œexperienceå…³é”®è¯: {experience_keywords[:3]}..."
            )
        else:
            print(f"   âŒ æ¨¡å—æ²¡æœ‰ KEYWORDS")
    except Exception as e:
        print(f"   âŒ æ£€æŸ¥å…³é”®è¯æ—¶å‡ºé”™: {e}")

    # 2. åŠ è½½å¹¶åˆ†æExcelæ–‡ä»¶å†…å®¹
    print(f"\nğŸ” åˆ†æExcelæ–‡ä»¶å†…å®¹: {test_file_path}")

    try:
        # ä½¿ç”¨ä¸è§£æå™¨ç›¸åŒçš„æ–¹æ³•åŠ è½½æ•°æ®
        all_data = await asyncio.to_thread(parser._load_excel_data, test_file_path)

        if not all_data:
            print("âŒ æ— æ³•åŠ è½½Excelæ•°æ®")
            return

        print(f"âœ… æˆåŠŸåŠ è½½ {len(all_data)} ä¸ªsheet")

        # åˆ†ææ¯ä¸ªsheetçš„å†…å®¹
        for i, data in enumerate(all_data):
            df = data["df"]
            sheet_name = data.get("sheet_name", f"Sheet{i}")

            print(f"\nğŸ“‹ Sheet: {sheet_name} ({df.shape[0]}è¡Œ x {df.shape[1]}åˆ—)")

            # æ˜¾ç¤ºå‰å‡ è¡Œå†…å®¹
            print("   å‰5è¡Œå†…å®¹:")
            for row_idx in range(min(5, len(df))):
                row_data = []
                for col_idx in range(min(df.shape[1], 5)):
                    cell_value = df.iloc[row_idx, col_idx]
                    if pd.notna(cell_value):
                        cell_str = str(cell_value)[:20]  # é™åˆ¶é•¿åº¦
                        row_data.append(f"'{cell_str}'")
                    else:
                        row_data.append("None")
                print(f"     è¡Œ{row_idx}: {' | '.join(row_data)}")

            # æœç´¢å…³é”®è¯ç›¸å…³çš„å†…å®¹
            print("   ğŸ” æœç´¢ç›¸å…³å…³é”®è¯:")

            # æ¥æ—¥ç›¸å…³
            arrival_keywords = ["æ¥æ—¥", "æ¸¡æ—¥", "å…¥å›½", "æ»åœ¨", "åœ¨æ—¥"]
            found_arrival = []

            for row_idx in range(len(df)):
                for col_idx in range(len(df.columns)):
                    cell = df.iloc[row_idx, col_idx]
                    if pd.notna(cell):
                        cell_str = str(cell)
                        for keyword in arrival_keywords:
                            if keyword in cell_str:
                                found_arrival.append(
                                    f"è¡Œ{row_idx}åˆ—{col_idx}: '{cell_str}'"
                                )

            if found_arrival:
                print(f"     âœ… æ‰¾åˆ°æ¥æ—¥ç›¸å…³å†…å®¹ ({len(found_arrival)}ä¸ª):")
                for item in found_arrival[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"       {item}")
            else:
                print(f"     âŒ æœªæ‰¾åˆ°æ¥æ—¥ç›¸å…³å†…å®¹")

            # ç»éªŒç›¸å…³
            experience_keywords = ["çµŒé¨“", "å®Ÿå‹™", "çµŒæ­´", "å¹´æ•°", "å¹´"]
            found_experience = []

            for row_idx in range(len(df)):
                for col_idx in range(len(df.columns)):
                    cell = df.iloc[row_idx, col_idx]
                    if pd.notna(cell):
                        cell_str = str(cell)
                        for keyword in experience_keywords:
                            if keyword in cell_str:
                                found_experience.append(
                                    f"è¡Œ{row_idx}åˆ—{col_idx}: '{cell_str}'"
                                )

            if found_experience:
                print(f"     âœ… æ‰¾åˆ°ç»éªŒç›¸å…³å†…å®¹ ({len(found_experience)}ä¸ª):")
                for item in found_experience[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"       {item}")
            else:
                print(f"     âŒ æœªæ‰¾åˆ°ç»éªŒç›¸å…³å†…å®¹")

    except Exception as e:
        print(f"âŒ åˆ†æExcelæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        traceback.print_exc()
        return

    # 3. æ‰‹åŠ¨æµ‹è¯•æå–å™¨
    print(f"\nğŸ”§ æ‰‹åŠ¨æµ‹è¯•æå–å™¨:")

    try:
        # æµ‹è¯•æ¥æ—¥å¹´ä»½æå–
        print("\nğŸ“ æµ‹è¯•æ¥æ—¥å¹´ä»½æå–å™¨:")
        arrival_result = arrival_extractor.extract(all_data, None)
        print(f"   ç»“æœ: {arrival_result}")
        print(f"   ç±»å‹: {type(arrival_result)}")

        # æµ‹è¯•ç»éªŒæå–
        print("\nğŸ“ æµ‹è¯•ç»éªŒæå–å™¨:")
        experience_result = experience_extractor.extract(all_data)
        print(f"   ç»“æœ: {experience_result}")
        print(f"   ç±»å‹: {type(experience_result)}")

    except Exception as e:
        print(f"âŒ æ‰‹åŠ¨æµ‹è¯•æå–å™¨æ—¶å‡ºé”™: {e}")
        traceback.print_exc()


def check_extractor_source_code():
    """æ£€æŸ¥æå–å™¨æºä»£ç """

    print("=== æ£€æŸ¥æå–å™¨æºä»£ç  ===\n")

    try:
        from app.services.extractors.arrival_year_extractor import ArrivalYearExtractor
        from app.services.extractors.experience_extractor import ExperienceExtractor

        # æ£€æŸ¥æ¥æ—¥å¹´ä»½æå–å™¨
        print("ğŸ” æ¥æ—¥å¹´ä»½æå–å™¨æºä»£ç æ£€æŸ¥:")

        # æ£€æŸ¥æ–‡ä»¶å†…å®¹
        import inspect

        arrival_file = inspect.getfile(ArrivalYearExtractor)
        print(f"   æ–‡ä»¶ä½ç½®: {arrival_file}")

        # è¯»å–å‰50è¡Œæ¥æŸ¥çœ‹å¯¼å…¥è¯­å¥
        with open(arrival_file, "r", encoding="utf-8") as f:
            lines = f.readlines()[:50]

        print("   å¯¼å…¥è¯­å¥:")
        for i, line in enumerate(lines):
            if "import" in line and ("KEYWORDS" in line or "constants" in line):
                print(f"     è¡Œ{i+1}: {line.strip()}")

        # æ£€æŸ¥ç»éªŒæå–å™¨
        print("\nğŸ” ç»éªŒæå–å™¨æºä»£ç æ£€æŸ¥:")

        experience_file = inspect.getfile(ExperienceExtractor)
        print(f"   æ–‡ä»¶ä½ç½®: {experience_file}")

        with open(experience_file, "r", encoding="utf-8") as f:
            lines = f.readlines()[:50]

        print("   å¯¼å…¥è¯­å¥:")
        for i, line in enumerate(lines):
            if "import" in line and ("KEYWORDS" in line or "constants" in line):
                print(f"     è¡Œ{i+1}: {line.strip()}")

    except Exception as e:
        print(f"âŒ æ£€æŸ¥æºä»£ç æ—¶å‡ºé”™: {e}")
        traceback.print_exc()


def create_patched_extractors():
    """åˆ›å»ºä¿®è¡¥ç‰ˆæœ¬çš„æå–å™¨"""

    print("=== åˆ›å»ºä¿®è¡¥ç‰ˆæœ¬çš„æå–å™¨ ===\n")

    # åˆ›å»ºä¿®è¡¥ç‰ˆçš„æ¥æ—¥å¹´ä»½æå–å™¨
    patched_arrival_content = '''# -*- coding: utf-8 -*-
"""æ¥æ—¥å¹´ä»½æå–å™¨ - ä¿®è¡¥ç‰ˆæœ¬ï¼šç›´æ¥å†…ç½®å…³é”®è¯"""

from typing import List, Dict, Any, Optional
from datetime import datetime
import pandas as pd
import re

# ç›´æ¥å®šä¹‰å…³é”®è¯ï¼Œé¿å…å¯¼å…¥é—®é¢˜
ARRIVAL_KEYWORDS = [
    "æ¥æ—¥", "æ¸¡æ—¥", "å…¥å›½", "æ—¥æœ¬æ»åœ¨å¹´æ•°", "æ»åœ¨å¹´æ•°", "åœ¨æ—¥å¹´æ•°",
    "æ¥æ—¥å¹´", "æ¥æ—¥æ™‚æœŸ", "æ¥æ—¥å¹´æœˆ", "æ¥æ—¥å¹´åº¦"
]

class ArrivalYearExtractorPatched:
    """æ¥æ—¥å¹´ä»½ä¿¡æ¯æå–å™¨ - ä¿®è¡¥ç‰ˆ"""

    def __init__(self):
        self.trans_table = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789")

    def extract(self, all_data: List[Dict[str, Any]], birthdate_result: Optional[str] = None) -> Optional[str]:
        """æå–æ¥æ—¥å¹´ä»½"""
        print(f"\\nğŸ” ä¿®è¡¥ç‰ˆæ¥æ—¥å¹´ä»½æå–å™¨å¼€å§‹å·¥ä½œ")
        print(f"   å…³é”®è¯: {ARRIVAL_KEYWORDS}")
        
        birth_year = None
        if birthdate_result:
            try:
                birth_year = datetime.strptime(birthdate_result, "%Y-%m-%d").year
                print(f"   æ’é™¤å‡ºç”Ÿå¹´ä»½: {birth_year}")
            except:
                pass

        candidates = []

        for data in all_data:
            df = data["df"]
            sheet_name = data.get("sheet_name", "Unknown")
            print(f"   å¤„ç†Sheet: {sheet_name}")

            # æ–¹æ³•1: æŸ¥æ‰¾"æ¥æ—¥XXå¹´"è¡¨è¿°
            for idx in range(min(40, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell):
                        cell_str = str(cell)
                        
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¥æ—¥å¹´æ•°è¡¨è¿°
                        patterns = [
                            (r"æ¥æ—¥.*?(\\d{1,2})\\s*å¹´", 3.5),
                            (r"åœ¨æ—¥.*?(\\d{1,2})\\s*å¹´", 3.0),
                            (r"æ»åœ¨.*?(\\d{1,2})\\s*å¹´", 2.5),
                        ]

                        for pattern, confidence in patterns:
                            match = re.search(pattern, cell_str)
                            if match:
                                years_in_japan = int(match.group(1))
                                if 1 <= years_in_japan <= 30:
                                    arrival_year = 2024 - years_in_japan
                                    candidates.append((str(arrival_year), confidence))
                                    print(f"   âœ… ä»'{cell_str}'æ¨ç®—æ¥æ—¥å¹´ä»½: {arrival_year}")

            # æ–¹æ³•2: æŸ¥æ‰¾å…³é”®è¯é™„è¿‘çš„å¹´ä»½
            for idx in range(min(40, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell):
                        cell_str = str(cell)
                        if any(k in cell_str for k in ARRIVAL_KEYWORDS):
                            print(f"   ğŸ” åœ¨è¡Œ{idx}åˆ—{col}æ‰¾åˆ°å…³é”®è¯: '{cell_str}'")
                            
                            # æœç´¢é™„è¿‘çš„å¹´ä»½
                            for r_off in range(-2, 5):
                                for c_off in range(-2, 15):
                                    r = idx + r_off
                                    c = col + c_off
                                    
                                    if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                        value = df.iloc[r, c]
                                        if pd.notna(value):
                                            year = self._parse_year(str(value))
                                            if year and 1990 <= year <= 2024 and year != birth_year:
                                                distance = abs(r_off) + abs(c_off)
                                                confidence = max(0.5, 2.0 - distance * 0.1)
                                                candidates.append((str(year), confidence))
                                                print(f"   âœ… åœ¨é™„è¿‘æ‰¾åˆ°å¹´ä»½: {year} (ç½®ä¿¡åº¦: {confidence:.2f})")

        if candidates:
            candidates.sort(key=lambda x: x[1], reverse=True)
            best_candidate = candidates[0]
            result = best_candidate[0]
            print(f"\\nâœ… æœ€ä½³æ¥æ—¥å¹´ä»½: {result} (ç½®ä¿¡åº¦: {best_candidate[1]:.2f})")
            return result

        print(f"\\nâŒ æœªèƒ½æå–åˆ°æ¥æ—¥å¹´ä»½")
        return None

    def _parse_year(self, value: str) -> Optional[int]:
        """è§£æå¹´ä»½å€¼"""
        value = value.strip().translate(self.trans_table)
        match = re.search(r'\\b(19|20)\\d{2}\\b', value)
        if match:
            return int(match.group())
        return None
'''

    # åˆ›å»ºä¿®è¡¥ç‰ˆçš„ç»éªŒæå–å™¨
    patched_experience_content = '''# -*- coding: utf-8 -*-
"""ç»éªŒæå–å™¨ - ä¿®è¡¥ç‰ˆæœ¬ï¼šç›´æ¥å†…ç½®å…³é”®è¯"""

from typing import List, Dict, Any, Optional
from datetime import datetime
import pandas as pd
import re

# ç›´æ¥å®šä¹‰å…³é”®è¯ï¼Œé¿å…å¯¼å…¥é—®é¢˜
EXPERIENCE_KEYWORDS = [
    "çµŒé¨“å¹´æ•°", "å®Ÿå‹™çµŒé¨“", "é–‹ç™ºçµŒé¨“", "ã‚½ãƒ•ãƒˆé–¢é€£æ¥­å‹™çµŒé¨“å¹´æ•°", "ITçµŒé¨“",
    "æ¥­å‹™çµŒé¨“", "çµŒé¨“", "å®Ÿå‹™å¹´æ•°", "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢çµŒé¨“", "çµŒé¨“å¹´æœˆ", "è·æ­´", "ITçµŒé¨“å¹´æ•°"
]

class ExperienceExtractorPatched:
    """ç»éªŒä¿¡æ¯æå–å™¨ - ä¿®è¡¥ç‰ˆ"""

    def __init__(self):
        self.trans_table = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789")

    def extract(self, all_data: List[Dict[str, Any]]) -> str:
        """æå–ç»éªŒå¹´æ•°"""
        print(f"\\nğŸ” ä¿®è¡¥ç‰ˆç»éªŒæå–å™¨å¼€å§‹å·¥ä½œ")
        print(f"   å…³é”®è¯: {EXPERIENCE_KEYWORDS[:5]}...")
        
        candidates = []

        for data in all_data:
            df = data["df"]
            sheet_name = data.get("sheet_name", "Unknown")
            print(f"   å¤„ç†Sheet: {sheet_name}")

            # æŸ¥æ‰¾ç»éªŒå…³é”®è¯
            for idx in range(min(60, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell):
                        cell_str = str(cell)
                        if any(k in cell_str for k in EXPERIENCE_KEYWORDS):
                            print(f"   ğŸ” åœ¨è¡Œ{idx}åˆ—{col}æ‰¾åˆ°å…³é”®è¯: '{cell_str}'")
                            
                            # æ’é™¤è¯´æ˜æ–‡å­—
                            if self._is_explanation_text(cell_str):
                                print(f"     è·³è¿‡è¯´æ˜æ–‡å­—")
                                continue

                            # æœç´¢é™„è¿‘çš„ç»éªŒå€¼
                            for r_off in range(-3, 6):
                                for c_off in range(-3, 20):
                                    r = idx + r_off
                                    c = col + c_off

                                    if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                        value = df.iloc[r, c]
                                        if pd.notna(value):
                                            exp = self._parse_experience_value(str(value))
                                            if exp:
                                                confidence = 1.0
                                                
                                                # æ ¹æ®å…³é”®è¯ç±»å‹è°ƒæ•´ç½®ä¿¡åº¦
                                                if "ã‚½ãƒ•ãƒˆé–¢é€£æ¥­å‹™çµŒé¨“å¹´æ•°" in cell_str:
                                                    confidence *= 3.0
                                                elif "ITçµŒé¨“å¹´æ•°" in cell_str:
                                                    confidence *= 2.5
                                                elif "å®Ÿå‹™çµŒé¨“" in cell_str:
                                                    confidence *= 2.0

                                                candidates.append((exp, confidence))
                                                print(f"     âœ… æ‰¾åˆ°ç»éªŒå€¼: {exp} (ç½®ä¿¡åº¦: {confidence:.2f})")

        if candidates:
            candidates.sort(key=lambda x: x[1], reverse=True)
            result = candidates[0][0]
            print(f"\\nâœ… æœ€ä½³ç»éªŒ: {result}")
            return result

        print(f"\\nâŒ æœªèƒ½æå–åˆ°ç»éªŒä¿¡æ¯")
        return ""

    def _parse_experience_value(self, value: str) -> Optional[str]:
        """è§£æç»éªŒå€¼"""
        value = str(value).strip()

        # æ’é™¤éç»éªŒå€¼
        if any(exclude in value for exclude in ["ä»¥ä¸Š", "æœªæº€", "â—", "â—‹", "â–³"]):
            return None

        # è½¬æ¢å…¨è§’æ•°å­—
        value = value.translate(self.trans_table)

        patterns = [
            (r"^(\\d+)\\s*å¹´\\s*(\\d+)\\s*ãƒ¶æœˆ$", lambda m: f"{m.group(1)}å¹´{m.group(2)}ãƒ¶æœˆ"),
            (r"^(\\d+(?:\\.\\d+)?)\\s*å¹´$", lambda m: f"{m.group(1)}å¹´"),
            (r"^(\\d+(?:\\.\\d+)?)\\s*$", lambda m: f"{m.group(1)}å¹´" if 1 <= float(m.group(1)) <= 40 else None),
            (r"(\\d+)\\s*å¹´", lambda m: f"{m.group(1)}å¹´"),
        ]

        for pattern, formatter in patterns:
            match = re.search(pattern, value)
            if match:
                result = formatter(match)
                if result:
                    return result

        return None

    def _is_explanation_text(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯è¯´æ˜æ–‡å­—"""
        explanations = ["ä»¥ä¸Š", "æœªæº€", "â—", "â—‹", "â–³", "æŒ‡å°", "ç²¾é€š", "ã§ãã‚‹"]
        return any(ex in text for ex in explanations)
'''

    try:
        # ä¿å­˜ä¿®è¡¥ç‰ˆæœ¬
        patches_dir = Path("debug_patches")
        patches_dir.mkdir(exist_ok=True)

        arrival_file = patches_dir / "arrival_year_extractor_patched.py"
        with open(arrival_file, "w", encoding="utf-8") as f:
            f.write(patched_arrival_content)

        experience_file = patches_dir / "experience_extractor_patched.py"
        with open(experience_file, "w", encoding="utf-8") as f:
            f.write(patched_experience_content)

        print(f"âœ… å·²åˆ›å»ºä¿®è¡¥ç‰ˆæœ¬:")
        print(f"   - {arrival_file}")
        print(f"   - {experience_file}")

        print(f"\\nğŸ’¡ ä½¿ç”¨ä¿®è¡¥ç‰ˆæœ¬æµ‹è¯•:")
        print(
            f"   from debug_patches.arrival_year_extractor_patched import ArrivalYearExtractorPatched"
        )
        print(
            f"   from debug_patches.experience_extractor_patched import ExperienceExtractorPatched"
        )

    except Exception as e:
        print(f"âŒ åˆ›å»ºä¿®è¡¥ç‰ˆæœ¬å¤±è´¥: {e}")


async def test_with_patched_extractors(test_file_path: str):
    """ä½¿ç”¨ä¿®è¡¥ç‰ˆæœ¬çš„æå–å™¨è¿›è¡Œæµ‹è¯•"""

    print("=== ä½¿ç”¨ä¿®è¡¥ç‰ˆæœ¬æå–å™¨æµ‹è¯• ===\\n")

    if not Path(test_file_path).exists():
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file_path}")
        return

    try:
        # å¯¼å…¥ä¿®è¡¥ç‰ˆæœ¬
        sys.path.append(str(Path("debug_patches")))
        from arrival_year_extractor_patched import ArrivalYearExtractorPatched
        from experience_extractor_patched import ExperienceExtractorPatched

        # åˆå§‹åŒ–ä¿®è¡¥ç‰ˆæå–å™¨
        arrival_extractor = ArrivalYearExtractorPatched()
        experience_extractor = ExperienceExtractorPatched()

        # åŠ è½½æ•°æ®ï¼ˆä½¿ç”¨åŸè§£æå™¨çš„æ–¹æ³•ï¼‰
        parser = ResumeParserService()
        all_data = await asyncio.to_thread(parser._load_excel_data, test_file_path)

        if not all_data:
            print("âŒ æ— æ³•åŠ è½½Excelæ•°æ®")
            return

        print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼Œå¼€å§‹ä½¿ç”¨ä¿®è¡¥ç‰ˆæå–å™¨æµ‹è¯•...")

        # æµ‹è¯•æ¥æ—¥å¹´ä»½æå–
        arrival_result = arrival_extractor.extract(all_data, None)

        # æµ‹è¯•ç»éªŒæå–
        experience_result = experience_extractor.extract(all_data)

        print(f"\\nğŸ¯ ä¿®è¡¥ç‰ˆæå–å™¨ç»“æœ:")
        print(f"   arrival_year_japan: {arrival_result}")
        print(f"   experience: {experience_result}")

        if arrival_result or experience_result:
            print(f"\\nâœ… ä¿®è¡¥ç‰ˆæå–å™¨å·¥ä½œæ­£å¸¸ï¼é—®é¢˜ç¡®å®æ˜¯å…³é”®è¯å¯¼å…¥ã€‚")
        else:
            print(f"\\nâŒ å³ä½¿ä¿®è¡¥ç‰ˆä¹Ÿæ— æ³•æå–ï¼Œå¯èƒ½æ˜¯æ•°æ®æ ¼å¼é—®é¢˜ã€‚")

    except Exception as e:
        print(f"âŒ æµ‹è¯•ä¿®è¡¥ç‰ˆæ—¶å‡ºé”™: {e}")
        traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ å¢å¼ºç‰ˆæå–å™¨è°ƒè¯•å·¥å…·")
    print("=" * 50)
    print("1. æ·±åº¦è°ƒè¯•æå–è¿‡ç¨‹ï¼ˆéœ€è¦æµ‹è¯•æ–‡ä»¶ï¼‰")
    print("2. æ£€æŸ¥æå–å™¨æºä»£ç ")
    print("3. åˆ›å»ºä¿®è¡¥ç‰ˆæœ¬çš„æå–å™¨")
    print("4. ä½¿ç”¨ä¿®è¡¥ç‰ˆæœ¬æµ‹è¯•ï¼ˆéœ€è¦æµ‹è¯•æ–‡ä»¶ï¼‰")
    print("5. é€€å‡º")

    while True:
        choice = input("\\nè¯·é€‰æ‹©æ“ä½œ (1-5): ").strip()

        if choice == "1":
            test_file = input("è¯·è¾“å…¥æµ‹è¯•æ–‡ä»¶è·¯å¾„: ").strip()
            if test_file:
                asyncio.run(deep_debug_extraction(test_file))
        elif choice == "2":
            check_extractor_source_code()
        elif choice == "3":
            create_patched_extractors()
        elif choice == "4":
            test_file = input("è¯·è¾“å…¥æµ‹è¯•æ–‡ä»¶è·¯å¾„: ").strip()
            if test_file:
                asyncio.run(test_with_patched_extractors(test_file))
        elif choice == "5":
            print("ğŸ‘‹ é€€å‡ºè°ƒè¯•å·¥å…·")
            break
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-5")


if __name__ == "__main__":
    main()
